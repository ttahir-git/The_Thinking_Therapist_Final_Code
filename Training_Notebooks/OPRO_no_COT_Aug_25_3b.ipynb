{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9563374a-57e2-4b4f-a49e-9da14f0b1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all folders in working directory, leave files alone\n",
    "!find . -mindepth 1 -maxdepth 1 -type d -exec rm -r {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41dab48f-5b86-4d48-ba01-dc5416adba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.8.9-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting unsloth_zoo>=2025.8.8 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.8.8-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.8.0.dev20250319+cu128)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting bitsandbytes (from unsloth)\n",
      "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (24.2)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-0.9.28-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3 (from unsloth)\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting datasets<4.0.0,>=3.4.1 (from unsloth)\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Downloading sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting tqdm (from unsloth)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.1.2)\n",
      "Collecting accelerate>=0.34.1 (from unsloth)\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
      "  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
      "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting protobuf (from unsloth)\n",
      "  Downloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Downloading diffusers-0.35.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.22.0.dev20250319+cu128)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
      "Collecting safetensors>=0.4.3 (from accelerate>=0.34.1->unsloth)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.16.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.3)\n",
      "Collecting xxhash (from datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=2.4.0->unsloth) (77.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth)\n",
      "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torchao (from unsloth_zoo>=2025.8.8->unsloth)\n",
      "  Downloading torchao-0.12.0-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.8.8->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.8.8->unsloth) (11.0.0)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.8.8->unsloth)\n",
      "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.8.0.87->torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.2.55->torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.3.41->torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: importlib_metadata in /usr/lib/python3/dist-packages (from diffusers->unsloth) (4.6.4)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=11.1.0 (from tyro->unsloth)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.1.31)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro->unsloth)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.16.0)\n",
      "Downloading unsloth-2025.8.9-py3-none-any.whl (311 kB)\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m174.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
      "Downloading sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m394.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m356.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m263.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.21.0-py3-none-any.whl (511 kB)\n",
      "Downloading unsloth_zoo-2025.8.8-py3-none-any.whl (184 kB)\n",
      "Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m189.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m241.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m337.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m318.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m233.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m260.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m329.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m343.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m334.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m329.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m362.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m320.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m220.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m302.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m337.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diffusers-0.35.1-py3-none-any.whl (4.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m366.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m330.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.28-py3-none-any.whl (129 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m335.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m339.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m209.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m404.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
      "Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m280.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchao-0.12.0-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m160.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "Installing collected packages: torchao, pytz, nvidia-cusparselt-cu12, xxhash, tzdata, typing-extensions, triton, tqdm, shtab, sentencepiece, safetensors, regex, pyarrow, protobuf, propcache, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multidict, msgspec, mdurl, hf-xet, hf_transfer, frozenlist, docstring-parser, dill, aiohappyeyeballs, yarl, typeguard, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, huggingface_hub, aiosignal, tokenizers, rich, nvidia-cusolver-cu12, diffusers, aiohttp, tyro, transformers, torch, xformers, torchvision, datasets, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.3\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.3:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.8.55\n",
      "    Uninstalling nvidia-nvtx-cu12-12.8.55:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.8.55\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.61\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.61:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.61\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.25.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.25.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.25.1\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.55\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.55:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.55\n",
      "  Attempting uninstall: nvidia-cufile-cu12\n",
      "    Found existing installation: nvidia-cufile-cu12 1.13.0.11\n",
      "    Uninstalling nvidia-cufile-cu12-1.13.0.11:\n",
      "      Successfully uninstalled nvidia-cufile-cu12-1.13.0.11\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.57\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.8.57:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.57\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.61\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.61:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.61\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.57\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.8.57:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.57\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.3.14\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.3.14:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.3.14\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.7.53\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.7.53:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.7.53\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.41\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.41:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.41\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.8.0.87\n",
      "    Uninstalling nvidia-cudnn-cu12-9.8.0.87:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.8.0.87\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.2.55\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.2.55:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.2.55\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.8.0.dev20250319+cu128\n",
      "    Uninstalling torch-2.8.0.dev20250319+cu128:\n",
      "      Successfully uninstalled torch-2.8.0.dev20250319+cu128\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.22.0.dev20250319+cu128\n",
      "    Uninstalling torchvision-0.22.0.dev20250319+cu128:\n",
      "      Successfully uninstalled torchvision-0.22.0.dev20250319+cu128\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0.dev20250319+cu128 requires torch==2.8.0.dev20250319, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.10.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 datasets-3.6.0 diffusers-0.35.1 dill-0.3.8 docstring-parser-0.17.0 frozenlist-1.7.0 hf-xet-1.1.8 hf_transfer-0.1.9 huggingface_hub-0.34.4 markdown-it-py-4.0.0 mdurl-0.1.2 msgspec-0.19.0 multidict-6.6.4 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pandas-2.3.2 peft-0.17.1 propcache-0.3.2 protobuf-6.32.0 pyarrow-21.0.0 pytz-2025.2 regex-2025.7.34 rich-14.1.0 safetensors-0.6.2 sentencepiece-0.2.1 shtab-1.7.2 tokenizers-0.21.4 torch-2.8.0 torchao-0.12.0 torchvision-0.23.0 tqdm-4.67.1 transformers-4.55.4 triton-3.4.0 trl-0.21.0 typeguard-4.4.4 typing-extensions-4.15.0 tyro-0.9.28 tzdata-2025.2 unsloth-2025.8.9 unsloth_zoo-2025.8.8 xformers-0.0.32.post2 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting instructor\n",
      "  Downloading instructor-1.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from instructor) (3.12.15)\n",
      "Collecting diskcache>=5.6.3 (from instructor)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor) (0.17.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from instructor) (3.1.4)\n",
      "Collecting jiter<0.11,>=0.6.1 (from instructor)\n",
      "  Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting openai<2.0.0,>=1.70.0 (from instructor)\n",
      "  Downloading openai-1.101.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting pydantic-core<3.0.0,>=2.18.0 (from instructor)\n",
      "  Downloading pydantic_core-2.39.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting pydantic<3.0.0,>=2.8.0 (from instructor)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from instructor) (2.32.3)\n",
      "Requirement already satisfied: rich<15.0.0,>=13.7.0 in /usr/local/lib/python3.11/dist-packages (from instructor) (14.1.0)\n",
      "Collecting tenacity<10.0.0,>=8.2.3 (from instructor)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typer<1.0.0,>=0.9.0 (from instructor)\n",
      "  Downloading typer-0.16.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor) (2.1.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.70.0->instructor) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.70.0->instructor) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.70.0->instructor) (0.28.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.70.0->instructor) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.70.0->instructor) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.70.0->instructor) (4.15.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.8.0->instructor)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core<3.0.0,>=2.18.0 (from instructor)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.8.0->instructor)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->instructor) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->instructor) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->instructor) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->instructor) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.7.0->instructor) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.7.0->instructor) (2.19.1)\n",
      "Collecting click>=8.0.0 (from typer<1.0.0,>=0.9.0->instructor)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.9.0->instructor)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.70.0->instructor) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.70.0->instructor) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.7.0->instructor) (0.1.2)\n",
      "Downloading instructor-1.10.0-py3-none-any.whl (119 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading openai-1.101.0-py3-none-any.whl (810 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.8/810.8 kB\u001b[0m \u001b[31m248.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m245.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typer-0.16.1-py3-none-any.whl (46 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, tenacity, shellingham, pydantic-core, jiter, diskcache, click, annotated-types, pydantic, typer, openai, instructor\n",
      "Successfully installed annotated-types-0.7.0 click-8.2.1 diskcache-5.6.3 instructor-1.10.0 jiter-0.10.0 openai-1.101.0 pydantic-2.11.7 pydantic-core-2.33.2 shellingham-1.5.4 tenacity-9.1.2 typer-0.16.1 typing-inspection-0.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.101.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.34.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (4.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.10.1.1-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from vllm) (2025.7.34)\n",
      "Collecting cachetools (from vllm)\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n",
      "Collecting blake3 (from vllm)\n",
      "  Downloading blake3-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.55.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.55.4)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.4)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (6.32.0)\n",
      "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.12.15)\n",
      "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.101.0)\n",
      "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.7)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.0.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
      "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm)\n",
      "  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n",
      "  Downloading lm_format_enforcer-0.10.12-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting llguidance<0.8.0,>=0.7.11 (from vllm)\n",
      "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting outlines_core==0.2.10 (from vllm)\n",
      "  Downloading outlines_core-0.2.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.11/dist-packages (from vllm) (5.6.3)\n",
      "Collecting lark==1.2.2 (from vllm)\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xgrammar==0.1.21 (from vllm)\n",
      "  Downloading xgrammar-0.1.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.15.0)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.16.1)\n",
      "Collecting partial-json-parser (from vllm)\n",
      "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (26.3.0)\n",
      "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\n",
      "Collecting gguf>=0.13.0 (from vllm)\n",
      "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting mistral_common>=1.8.2 (from mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading mistral_common-1.8.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
      "Collecting einops (from vllm)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting compressed-tensors==0.10.2 (from vllm)\n",
      "  Downloading compressed_tensors-0.10.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting depyf==0.19.0 (from vllm)\n",
      "  Downloading depyf-0.19.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting cloudpickle (from vllm)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchfiles (from vllm)\n",
      "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\n",
      "Collecting scipy (from vllm)\n",
      "  Downloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting pybase64 (from vllm)\n",
      "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting cbor2 (from vllm)\n",
      "  Downloading cbor2-5.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting setproctitle (from vllm)\n",
      "  Downloading setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting openai-harmony>=0.0.3 (from vllm)\n",
      "  Downloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Collecting numba==0.61.2 (from vllm)\n",
      "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)\n",
      "  Downloading ray-2.48.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting torch==2.7.1 (from vllm)\n",
      "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchaudio==2.7.1 (from vllm)\n",
      "  Downloading torchaudio-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchvision==0.22.1 (from vllm)\n",
      "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting xformers==0.0.31 (from vllm)\n",
      "  Downloading xformers-0.0.31-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting astor (from depyf==0.19.0->vllm)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.3.8)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.1->vllm)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch==2.7.1->vllm)\n",
      "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch==2.7.1->vllm) (77.0.1)\n",
      "Collecting starlette<0.48.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading starlette-0.47.3-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi_cli-0.0.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
      "Collecting jinja2 (from torch==2.7.1->vllm)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer<0.11,>=0.10.11->vllm)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer<0.11,>=0.10.11->vllm) (24.2)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.23.0)\n",
      "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.99.1->vllm) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.99.1->vllm) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.99.1->vllm) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.99.1->vllm) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.4.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (8.2.1)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm)\n",
      "  Downloading msgpack-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting cupy-cuda12x (from ray[cgraph]>=2.48.0->vllm)\n",
      "  Downloading cupy_cuda12x-13.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.1.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.21.1->vllm) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.0->vllm) (0.6.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.1)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.16.1)\n",
      "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rich_toolkit-0.15.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi_cloud_cli-0.1.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.21.1->vllm) (1.1.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.1->vllm) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.23.1)\n",
      "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.1->vllm) (1.3.0)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm)\n",
      "  Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting soxr>=0.5.0 (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting sentry-sdk>=2.20.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading sentry_sdk-2.35.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.17.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
      "Downloading vllm-0.10.1.1-cp38-abi3-manylinux1_x86_64.whl (414.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.4/414.4 MB\u001b[0m \u001b[31m137.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading compressed_tensors-0.10.2-py3-none-any.whl (169 kB)\n",
      "Downloading depyf-0.19.0-py3-none-any.whl (39 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m351.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outlines_core-0.2.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m246.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m135.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m183.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m203.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.31-cp39-abi3-manylinux_2_28_x86_64.whl (117.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m167.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m293.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m360.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m203.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m199.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m205.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m283.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m188.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m122.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m277.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m218.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m245.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m353.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m149.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
      "Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m369.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lm_format_enforcer-0.10.12-py3-none-any.whl (44 kB)\n",
      "Downloading mistral_common-1.8.4-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m383.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m389.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m346.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading ray-2.48.0-cp311-cp311-manylinux2014_x86_64.whl (70.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m205.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blake3-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading cbor2-5.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (254 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "Downloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m380.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading fastapi_cli-0.0.8-py3-none-any.whl (10 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m431.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (429 kB)\n",
      "Downloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading starlette-0.47.3-py3-none-any.whl (72 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading cupy_cuda12x-13.6.0-cp311-cp311-manylinux2014_x86_64.whl (113.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading fastapi_cloud_cli-0.1.5-py3-none-any.whl (18 kB)\n",
      "Downloading fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m285.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich_toolkit-0.15.0-py3-none-any.whl (29 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m260.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m402.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (950 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.6/950.6 kB\u001b[0m \u001b[31m253.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.35.0-py2.py3-none-any.whl (363 kB)\n",
      "Installing collected packages: py-cpuinfo, nvidia-cusparselt-cu12, fastrlock, blake3, websockets, uvloop, uvicorn, triton, soxr, setproctitle, sentry-sdk, scipy, rignore, python-multipart, pycountry, pybase64, partial-json-parser, outlines_core, opencv-python-headless, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, msgpack, llvmlite, llguidance, lark, jinja2, interegular, httptools, gguf, einops, dnspython, cupy-cuda12x, cloudpickle, cbor2, cachetools, astor, watchfiles, tiktoken, starlette, soundfile, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, email-validator, depyf, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai-harmony, nvidia-cusolver-cu12, lm-format-enforcer, fastapi, torch, ray, fastapi-cloud-cli, fastapi-cli, xgrammar, xformers, torchvision, torchaudio, mistral_common, compressed-tensors, vllm\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.4.0\n",
      "    Uninstalling triton-3.4.0:\n",
      "      Successfully uninstalled triton-3.4.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
      "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufile-cu12\n",
      "    Found existing installation: nvidia-cufile-cu12 1.13.1.3\n",
      "    Uninstalling nvidia-cufile-cu12-1.13.1.3:\n",
      "      Successfully uninstalled nvidia-cufile-cu12-1.13.1.3\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
      "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.8.0\n",
      "    Uninstalling torch-2.8.0:\n",
      "      Successfully uninstalled torch-2.8.0\n",
      "  Attempting uninstall: xformers\n",
      "    Found existing installation: xformers 0.0.32.post2\n",
      "    Uninstalling xformers-0.0.32.post2:\n",
      "      Successfully uninstalled xformers-0.0.32.post2\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.23.0\n",
      "    Uninstalling torchvision-0.23.0:\n",
      "      Successfully uninstalled torchvision-0.23.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.6.0.dev20250319+cu128\n",
      "    Uninstalling torchaudio-2.6.0.dev20250319+cu128:\n",
      "      Successfully uninstalled torchaudio-2.6.0.dev20250319+cu128\n",
      "Successfully installed astor-0.8.1 blake3-1.0.5 cachetools-6.2.0 cbor2-5.7.0 cloudpickle-3.1.1 compressed-tensors-0.10.2 cupy-cuda12x-13.6.0 depyf-0.19.0 dnspython-2.7.0 einops-0.8.1 email-validator-2.2.0 fastapi-0.116.1 fastapi-cli-0.0.8 fastapi-cloud-cli-0.1.5 fastrlock-0.8.3 gguf-0.17.1 httptools-0.6.4 interegular-0.3.3 jinja2-3.1.6 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.10.12 mistral_common-1.8.4 msgpack-1.1.1 ninja-1.13.0 numba-0.61.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 openai-harmony-0.0.4 opencv-python-headless-4.12.0.88 outlines_core-0.2.10 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 py-cpuinfo-9.0.0 pybase64-1.4.2 pycountry-24.6.1 pydantic-extra-types-2.10.5 python-multipart-0.0.20 ray-2.48.0 rich-toolkit-0.15.0 rignore-0.6.4 scipy-1.16.1 sentry-sdk-2.35.0 setproctitle-1.3.6 soundfile-0.13.1 soxr-0.5.0.post1 starlette-0.47.3 tiktoken-0.11.0 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1 triton-3.3.1 uvicorn-0.35.0 uvloop-0.21.0 vllm-0.10.1.1 watchfiles-1.1.0 websockets-15.0.1 xformers-0.0.31 xgrammar-0.1.21\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth\n",
    "!pip install instructor\n",
    "!pip install openai\n",
    "!pip install pydantic\n",
    "!pip install dotenv\n",
    "!pip install huggingface_hub\n",
    "!python -m pip install --upgrade typing_extensions\n",
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ebc31-9312-4d42-be5a-dd9ffbe85647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 08-25 23:28:31 [__init__.py:241] Automatically detected platform cuda.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "OpenRouter API key provided. Initializing ASYNC client for generating 'rejected' responses...\n",
      "Async OpenRouter client initialized successfully.\n",
      "Qwen API key provided. Initializing ASYNC client for generating 'chosen' responses...\n",
      "Async Qwen client initialized successfully.\n",
      "Loading base model and tokenizer...\n",
      "==((====))==  Unsloth 2025.8.9: Fast Llama patching. Transformers: 4.55.4. vLLM: 0.10.1.1.\n",
      "   \\\\   /|    NVIDIA RTX A5000. Num GPUs = 1. Max memory: 23.547 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b204f1c7067450185fe213bb6d4d5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9825f22f2f44f5b9ceaf622d6fad143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61d605c0ef7415fa02514c5bdc5f4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2dd22b54aea4aefb01548558c93eeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0320014381a9471f8cb815bd417f7962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad27750679ec42b8a0b40dbe39402f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5acbf079c04d8f8335aaf7d2fd99f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79d4210c3ca443e8f6b3601f6019243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011ccffcd21d446cbe57d5c9b9880009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40844143dcf84191b85e5f4c101e8e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PEFT (LoRA)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.9 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and LoRA setup complete.\n",
      "File 'combined_unsloth_dataset.json' already exists. Skipping download.\n",
      "Found running event loop. Awaiting data preparation...\n",
      "Loading and processing base data from combined_unsloth_dataset.json...\n",
      "Loaded 1250 entries.\n",
      "Skipped 0 entries (Format: 0, Role: 0, No User Msg: 0).\n",
      "Base data for ORPO prepared.\n",
      "Generating preference pairs concurrently using Qwen (chosen) and OpenRouter (rejected)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Preference Pairs: 100%|██████████| 1250/1250 [20:32<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated 1250 preference pairs out of 1250 total.\n",
      "Saved preference dataset to orpo_preference_dataset.json\n",
      "\n",
      "Example data point (after processing for ORPO):\n",
      "Prompt Messages (first 3):\n",
      "  Role: system, Content: You are an AI simulating an Acceptance and Commitment Therapy (ACT) therapist. Your primary goal is ...\n",
      "  Role: user, Content: I don't even know where to start. I've been feeling so overwhelmed lately. It's like everything sets...\n",
      "\n",
      "Chosen Response (from Qwen):\n",
      "  That sounds really tough—like you're carrying a lot right now. When anger shows up at work, what happens *inside* you as you try to keep it together? Like, what does that struggle feel like in your body or your mind?...\n",
      "\n",
      "Rejected Response (from OpenRouter):\n",
      "  It sounds like you're feeling a bit like you're at the end of your rope. Can you tell me more about what happens when you start to feel overwhelmed or angry? What's the first thing that comes up for you, like a trigger or a thought pattern?...\n",
      "Configuring ORPOTrainer...\n",
      "MAX_SEQ_LENGTH: 9000\n",
      "Effective Max Prompt Length: 5400\n",
      "Effective Max Length (Prompt + Completion): 9000\n",
      "Logging training metrics to: act-therapist-orpo-llama31-3b/training_log.tsv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ff3787a8a741c08efa1a6e82046b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404c5a7a3fc745e5a7c7fde625529aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd5713e77d047cd8dab8cc3f972e0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORPOTrainer configured.\n",
      "Starting ORPO training...\n",
      "No valid checkpoint found in act-therapist-orpo-llama31-3b. Starting training from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,250 | Num Epochs = 1 | Total steps = 157\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 03:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>rewards / chosen</th>\n",
       "      <th>rewards / rejected</th>\n",
       "      <th>rewards / accuracies</th>\n",
       "      <th>rewards / margins</th>\n",
       "      <th>logps / rejected</th>\n",
       "      <th>logps / chosen</th>\n",
       "      <th>logits / rejected</th>\n",
       "      <th>logits / chosen</th>\n",
       "      <th>log_odds_ratio</th>\n",
       "      <th>log_odds_chosen</th>\n",
       "      <th>eval_logits / chosen</th>\n",
       "      <th>eval_logits / rejected</th>\n",
       "      <th>nll_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.718800</td>\n",
       "      <td>-0.354775</td>\n",
       "      <td>-0.197656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.157119</td>\n",
       "      <td>-1.976556</td>\n",
       "      <td>-3.547747</td>\n",
       "      <td>-0.555354</td>\n",
       "      <td>-0.754063</td>\n",
       "      <td>-1.881846</td>\n",
       "      <td>-1.696997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.530659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.641800</td>\n",
       "      <td>-0.350289</td>\n",
       "      <td>-0.201173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.149116</td>\n",
       "      <td>-2.011730</td>\n",
       "      <td>-3.502893</td>\n",
       "      <td>-0.569961</td>\n",
       "      <td>-0.937328</td>\n",
       "      <td>-1.812801</td>\n",
       "      <td>-1.610139</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.460490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.672800</td>\n",
       "      <td>-0.357482</td>\n",
       "      <td>-0.201302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.156180</td>\n",
       "      <td>-2.013024</td>\n",
       "      <td>-3.574820</td>\n",
       "      <td>-0.571431</td>\n",
       "      <td>-0.925903</td>\n",
       "      <td>-1.887081</td>\n",
       "      <td>-1.682965</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.484098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.584900</td>\n",
       "      <td>-0.347806</td>\n",
       "      <td>-0.206939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.140867</td>\n",
       "      <td>-2.069393</td>\n",
       "      <td>-3.478060</td>\n",
       "      <td>-0.577680</td>\n",
       "      <td>-0.835109</td>\n",
       "      <td>-1.748414</td>\n",
       "      <td>-1.521709</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.410082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.699400</td>\n",
       "      <td>-0.353797</td>\n",
       "      <td>-0.197486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.156311</td>\n",
       "      <td>-1.974858</td>\n",
       "      <td>-3.537965</td>\n",
       "      <td>-0.579759</td>\n",
       "      <td>-1.033584</td>\n",
       "      <td>-1.889855</td>\n",
       "      <td>-1.694976</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.510384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.487600</td>\n",
       "      <td>-0.331541</td>\n",
       "      <td>-0.191606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.139935</td>\n",
       "      <td>-1.916063</td>\n",
       "      <td>-3.315412</td>\n",
       "      <td>-0.595315</td>\n",
       "      <td>-0.861502</td>\n",
       "      <td>-1.741609</td>\n",
       "      <td>-1.528738</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.313390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.438300</td>\n",
       "      <td>-0.329969</td>\n",
       "      <td>-0.187834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.142136</td>\n",
       "      <td>-1.878335</td>\n",
       "      <td>-3.299694</td>\n",
       "      <td>-0.725412</td>\n",
       "      <td>-0.870489</td>\n",
       "      <td>-1.780744</td>\n",
       "      <td>-1.565098</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.260201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.425300</td>\n",
       "      <td>-0.328379</td>\n",
       "      <td>-0.190775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.137605</td>\n",
       "      <td>-1.907745</td>\n",
       "      <td>-3.283792</td>\n",
       "      <td>-0.402315</td>\n",
       "      <td>-0.987175</td>\n",
       "      <td>-1.722810</td>\n",
       "      <td>-1.507088</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.253009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.340600</td>\n",
       "      <td>-0.318256</td>\n",
       "      <td>-0.177877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.140379</td>\n",
       "      <td>-1.778771</td>\n",
       "      <td>-3.182561</td>\n",
       "      <td>-0.515766</td>\n",
       "      <td>-1.008372</td>\n",
       "      <td>-1.765825</td>\n",
       "      <td>-1.553621</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.163993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.277500</td>\n",
       "      <td>-0.315338</td>\n",
       "      <td>-0.181790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.133548</td>\n",
       "      <td>-1.817897</td>\n",
       "      <td>-3.153380</td>\n",
       "      <td>-0.494300</td>\n",
       "      <td>-0.888192</td>\n",
       "      <td>-1.698244</td>\n",
       "      <td>-1.473319</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.107691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>3.239000</td>\n",
       "      <td>-0.311028</td>\n",
       "      <td>-0.175724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.135304</td>\n",
       "      <td>-1.757241</td>\n",
       "      <td>-3.110283</td>\n",
       "      <td>-0.445779</td>\n",
       "      <td>-0.823232</td>\n",
       "      <td>-1.729751</td>\n",
       "      <td>-1.503641</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.066030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.056800</td>\n",
       "      <td>-0.292099</td>\n",
       "      <td>-0.177053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.115046</td>\n",
       "      <td>-1.770527</td>\n",
       "      <td>-2.920987</td>\n",
       "      <td>-0.554990</td>\n",
       "      <td>-0.788355</td>\n",
       "      <td>-1.555747</td>\n",
       "      <td>-1.295884</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.901218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>3.032400</td>\n",
       "      <td>-0.288376</td>\n",
       "      <td>-0.166536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.121840</td>\n",
       "      <td>-1.665357</td>\n",
       "      <td>-2.883761</td>\n",
       "      <td>-0.368993</td>\n",
       "      <td>-0.723791</td>\n",
       "      <td>-1.618695</td>\n",
       "      <td>-1.377427</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.870510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.934900</td>\n",
       "      <td>-0.283248</td>\n",
       "      <td>-0.172576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.110673</td>\n",
       "      <td>-1.725756</td>\n",
       "      <td>-2.832484</td>\n",
       "      <td>-0.433871</td>\n",
       "      <td>-0.551892</td>\n",
       "      <td>-1.520080</td>\n",
       "      <td>-1.247012</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.782852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.885300</td>\n",
       "      <td>-0.274733</td>\n",
       "      <td>-0.167546</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.107187</td>\n",
       "      <td>-1.675465</td>\n",
       "      <td>-2.747330</td>\n",
       "      <td>-0.384478</td>\n",
       "      <td>-0.635452</td>\n",
       "      <td>-1.496960</td>\n",
       "      <td>-1.218618</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.735619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.876400</td>\n",
       "      <td>-0.276716</td>\n",
       "      <td>-0.179263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.097452</td>\n",
       "      <td>-1.792635</td>\n",
       "      <td>-2.767155</td>\n",
       "      <td>-0.453995</td>\n",
       "      <td>-0.523359</td>\n",
       "      <td>-1.403557</td>\n",
       "      <td>-1.095959</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.736018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>2.823500</td>\n",
       "      <td>-0.270635</td>\n",
       "      <td>-0.180133</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.090502</td>\n",
       "      <td>-1.801325</td>\n",
       "      <td>-2.706347</td>\n",
       "      <td>-0.274814</td>\n",
       "      <td>-0.530121</td>\n",
       "      <td>-1.349405</td>\n",
       "      <td>-1.023448</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.688549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.776100</td>\n",
       "      <td>-0.263928</td>\n",
       "      <td>-0.170390</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.093538</td>\n",
       "      <td>-1.703901</td>\n",
       "      <td>-2.639282</td>\n",
       "      <td>-0.411725</td>\n",
       "      <td>-0.456945</td>\n",
       "      <td>-1.388852</td>\n",
       "      <td>-1.073476</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.637255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>2.817000</td>\n",
       "      <td>-0.267283</td>\n",
       "      <td>-0.173708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.093575</td>\n",
       "      <td>-1.737079</td>\n",
       "      <td>-2.672826</td>\n",
       "      <td>-0.120374</td>\n",
       "      <td>-0.414479</td>\n",
       "      <td>-1.381470</td>\n",
       "      <td>-1.067254</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.678832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.728300</td>\n",
       "      <td>-0.258422</td>\n",
       "      <td>-0.170803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.087619</td>\n",
       "      <td>-1.708026</td>\n",
       "      <td>-2.584218</td>\n",
       "      <td>-0.226540</td>\n",
       "      <td>-0.542922</td>\n",
       "      <td>-1.331397</td>\n",
       "      <td>-1.003365</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.595180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>2.704200</td>\n",
       "      <td>-0.257971</td>\n",
       "      <td>-0.171038</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.086933</td>\n",
       "      <td>-1.710383</td>\n",
       "      <td>-2.579713</td>\n",
       "      <td>-0.149352</td>\n",
       "      <td>-0.346831</td>\n",
       "      <td>-1.348884</td>\n",
       "      <td>-0.998356</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.569290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.763100</td>\n",
       "      <td>-0.263146</td>\n",
       "      <td>-0.161013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.102133</td>\n",
       "      <td>-1.610129</td>\n",
       "      <td>-2.631461</td>\n",
       "      <td>-0.089672</td>\n",
       "      <td>-0.517157</td>\n",
       "      <td>-1.457051</td>\n",
       "      <td>-1.176348</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.617443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2.654600</td>\n",
       "      <td>-0.252262</td>\n",
       "      <td>-0.161951</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.090311</td>\n",
       "      <td>-1.619510</td>\n",
       "      <td>-2.522621</td>\n",
       "      <td>-0.171735</td>\n",
       "      <td>-0.448341</td>\n",
       "      <td>-1.369458</td>\n",
       "      <td>-1.044990</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.517684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.691700</td>\n",
       "      <td>-0.254362</td>\n",
       "      <td>-0.171325</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.083037</td>\n",
       "      <td>-1.713253</td>\n",
       "      <td>-2.543623</td>\n",
       "      <td>-0.287512</td>\n",
       "      <td>-0.308494</td>\n",
       "      <td>-1.303619</td>\n",
       "      <td>-0.952080</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.561369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.636700</td>\n",
       "      <td>-0.255000</td>\n",
       "      <td>-0.168284</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.086716</td>\n",
       "      <td>-1.682839</td>\n",
       "      <td>-2.550001</td>\n",
       "      <td>-0.260417</td>\n",
       "      <td>-0.525296</td>\n",
       "      <td>-1.346065</td>\n",
       "      <td>-0.998176</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.502102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.570500</td>\n",
       "      <td>-0.245427</td>\n",
       "      <td>-0.182966</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>-0.062461</td>\n",
       "      <td>-1.829658</td>\n",
       "      <td>-2.454266</td>\n",
       "      <td>-0.478907</td>\n",
       "      <td>-0.173144</td>\n",
       "      <td>-1.146401</td>\n",
       "      <td>-0.719221</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.455870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>2.663000</td>\n",
       "      <td>-0.256295</td>\n",
       "      <td>-0.169949</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.086346</td>\n",
       "      <td>-1.699491</td>\n",
       "      <td>-2.562953</td>\n",
       "      <td>-0.104458</td>\n",
       "      <td>-0.687474</td>\n",
       "      <td>-1.321379</td>\n",
       "      <td>-0.987535</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.530894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.713500</td>\n",
       "      <td>-0.260647</td>\n",
       "      <td>-0.166239</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.094408</td>\n",
       "      <td>-1.662394</td>\n",
       "      <td>-2.606474</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>-0.363561</td>\n",
       "      <td>-1.399215</td>\n",
       "      <td>-1.082516</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.573540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2.589100</td>\n",
       "      <td>-0.248037</td>\n",
       "      <td>-0.177411</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.070626</td>\n",
       "      <td>-1.774110</td>\n",
       "      <td>-2.480370</td>\n",
       "      <td>-0.107196</td>\n",
       "      <td>-0.391311</td>\n",
       "      <td>-1.196072</td>\n",
       "      <td>-0.807169</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.469451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.531400</td>\n",
       "      <td>-0.243808</td>\n",
       "      <td>-0.181926</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>-0.061882</td>\n",
       "      <td>-1.819260</td>\n",
       "      <td>-2.438083</td>\n",
       "      <td>-0.201685</td>\n",
       "      <td>-0.347382</td>\n",
       "      <td>-1.130769</td>\n",
       "      <td>-0.710873</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.418296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>2.569800</td>\n",
       "      <td>-0.246804</td>\n",
       "      <td>-0.180136</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.066668</td>\n",
       "      <td>-1.801364</td>\n",
       "      <td>-2.468042</td>\n",
       "      <td>-0.191043</td>\n",
       "      <td>-0.164900</td>\n",
       "      <td>-1.159352</td>\n",
       "      <td>-0.759080</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.453886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training log saved to: act-therapist-orpo-llama31-3b/training_log.tsv\n",
      "Training finished!\n",
      "\n",
      "--- Saving Final Adapter ---\n",
      "Final LoRA adapter and tokenizer saved to act-therapist-orpo-llama31-3b/final_adapter\n",
      "\n",
      "--- Uploading to Hugging Face Hub ---\n",
      "Attempting to create/access private repo: TTahir/act-therapist-orpo-llama31-3b-2025-08-25\n",
      "Repo 'TTahir/act-therapist-orpo-llama31-3b-2025-08-25' ensured.\n",
      "Uploading final adapter folder 'act-therapist-orpo-llama31-3b/final_adapter'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69675984587b459bb1327b9c1c76e33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99a1a3b9ef44eb092b36a682c4537c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b02a24c2b644beaae2dfc1f701b5983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...a31-3b/final_adapter/tokenizer.json: 100%|##########| 17.2MB / 17.2MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be6df4958b04ba3b1c95c1b13e26952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...l_adapter/adapter_model.safetensors:   0%|          | 46.4kB /  389MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final adapter uploaded.\n",
      "Uploading preference dataset file 'orpo_preference_dataset.json'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8300b1581d4141f1ae9c9c886c8abbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb54cedf8294559973cbf1d52faa85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b5dc1efd874a01af25ea0ad75ab2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  orpo_preference_dataset.json          :  88%|########8 | 13.8MB / 15.6MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading training log file 'act-therapist-orpo-llama31-3b/training_log.tsv'...\n",
      "Uploading training script 'ipykernel_launcher.py'...\n",
      "Successfully uploaded artifacts to private repo: https://huggingface.co/TTahir/act-therapist-orpo-llama31-3b-2025-08-25\n",
      "\n",
      "--- Inference Example ---\n",
      "LoRA adapters merged for inference.\n",
      "\n",
      "Generating response for prompt: 'I keep having this thought that I'm a complete failure, and it just spirals.'\n",
      "\n",
      "Generated ACT Response (Cleaned Model Output):\n",
      "That thought can be really intense. What happens when you notice that \"failure\" thought showing up, right in the moment?\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from huggingface_hub import HfApi, create_repo, upload_folder, upload_file\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI, RateLimitError, APIError\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import random\n",
    "\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from trl import ORPOConfig, ORPOTrainer\n",
    "from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "MAX_SEQ_LENGTH = 9000\n",
    "LORA_RANK = 64\n",
    "JSON_DATA_PATH = \"combined_unsloth_dataset.json\"\n",
    "PREFERENCE_DATA_PATH = \"orpo_preference_dataset.json\"\n",
    "\n",
    "OPENROUTER_API_KEY = \"\"\n",
    "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "OPENROUTER_MODEL_REJECTED = \"meta-llama/llama-3.2-3b-instruct\"\n",
    "\n",
    "QWEN_API_KEY = \"\"\n",
    "QWEN_BASE_URL = \"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    "QWEN_MODEL = \"qwen3-235b-a22b-thinking-2507\"\n",
    "\n",
    "HF_USERNAME = \"TTahir\"\n",
    "HF_REPO_NAME_TEMPLATE = f\"{HF_USERNAME}/act-therapist-orpo-llama31-3b-{{date}}\"\n",
    "HF_TOKEN = \"\"\n",
    "\n",
    "KEYWORD_THINKING = \"Thinking:\"\n",
    "KEYWORD_ANSWER = \"Answer:\"\n",
    "\n",
    "OLD_THINKING_TAG = \"<|thinking|>\"\n",
    "OLD_ANSWER_TAG = \"<|answer|>\"\n",
    "\n",
    "OUTPUT_DIR = \"act-therapist-orpo-llama31-3b\"\n",
    "LOG_FILE_PATH = os.path.join(OUTPUT_DIR, \"training_log.tsv\")\n",
    "\n",
    "openrouter_client = None\n",
    "if OPENROUTER_API_KEY and OPENROUTER_BASE_URL:\n",
    "    print(\"OpenRouter API key provided. Initializing ASYNC client for generating 'rejected' responses...\")\n",
    "    try:\n",
    "        openrouter_client = AsyncOpenAI(\n",
    "            base_url=OPENROUTER_BASE_URL,\n",
    "            api_key=OPENROUTER_API_KEY,\n",
    "        )\n",
    "        print(\"Async OpenRouter client initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Error initializing Async OpenRouter client: {e}. Setting client to None.\")\n",
    "        openrouter_client = None\n",
    "else:\n",
    "    print(\"OpenRouter API key or base URL missing. Cannot generate rejected responses for ORPO.\")\n",
    "    openrouter_client = None\n",
    "\n",
    "qwen_client = None\n",
    "if QWEN_API_KEY and QWEN_BASE_URL:\n",
    "    print(\"Qwen API key provided. Initializing ASYNC client for generating 'chosen' responses...\")\n",
    "    try:\n",
    "        qwen_client = AsyncOpenAI(\n",
    "            base_url=QWEN_BASE_URL,\n",
    "            api_key=QWEN_API_KEY,\n",
    "        )\n",
    "        print(\"Async Qwen client initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Error initializing Async Qwen client: {e}. Setting client to None.\")\n",
    "        qwen_client = None\n",
    "else:\n",
    "    print(\"Qwen API key or base URL missing. Cannot generate chosen responses for ORPO.\")\n",
    "    qwen_client = None\n",
    "\n",
    "print(\"Loading base model and tokenizer...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    load_in_4bit=False,\n",
    "    fast_inference=False,\n",
    "    max_lora_rank=LORA_RANK*2,\n",
    "    gpu_memory_utilization = 0.9\n",
    ")\n",
    "assert model is not None and tokenizer is not None, \"Model or tokenizer failed to load.\"\n",
    "\n",
    "print(\"Applying PEFT (LoRA)...\")\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=LORA_RANK,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=LORA_RANK,\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    ")\n",
    "print(\"Model and LoRA setup complete.\")\n",
    "\n",
    "therapist_system_prompt = f\"\"\"You are an AI simulating an Acceptance and Commitment Therapy (ACT) therapist. Your primary goal is to guide the patient toward psychological flexibility by helping them change their relationship with their thoughts and feelings, connect with their values, and take committed action. You facilitate movement without giving direct advice.\n",
    "\n",
    "Your response should be a natural, concise, and have a single focus. If exploring, ask a direct, open-ended question. If validating, do it briefly and then move to your exploratory question or ACT-aligned statement.\n",
    "\n",
    "Core Directives for your response:\n",
    "1. MAINTAIN A COLLABORATIVE, NON-JUDGMENTAL STANCE:\n",
    "    * Your role is a curious and compassionate guide, not a coach, judge, or expert giving advice.\n",
    "    * DO NOT give advice (e.g., \"You should try...\"). Instead, explore possibilities (\"What might happen if...\").\n",
    "    * DO NOT use praise or cheerleading (e.g., \"I'm proud of you,\" \"That's a great job!\"). Instead, acknowledge the patient's effort and connect it back to their values (\"Taking that step, even though it was hard, seems really connected to that value of...\").\n",
    "2. PRACTICE PURE ACT - NO CBT:\n",
    "    * Your primary goal is to foster acceptance and defusion, not to change or dispute the content of thoughts.\n",
    "    * AVOID COGNITIVE REFRAMING. Do not suggest changing a negative thought into a neutral or positive one.\n",
    "    * INSTEAD OF REFRAMING, USE DEFUSION. Help the patient notice their thoughts as thoughts (e.g., \"So the 'I am a failure' story shows up then,\" or \"Can you thank your mind for that 'helpful' warning?\"). The goal is to see the thought, not believe it or change it.\n",
    "3. THE ACT PIVOT - FROM PROBLEM TO PROCESS:\n",
    "    * After 1-2 questions exploring a problem, look for where the patient's current strategy is unworkable (\"it's exhausting,\" \"it's not helping\").\n",
    "    * CRITICAL PIVOT: Once unworkability is clear, pivot from analyzing the problem to introducing an ACT process. Move from asking \"Why do you feel X?\" to \"What would it be like to make room for X, if it meant you could do Y (valued action)?\".\n",
    "4. INTRODUCE EXPERIENTIAL WORK NATURALLY:\n",
    "    * When introducing a mindfulness or acceptance exercise, frame it as a small, low-stakes experiment.\n",
    "    * Gain buy-in first: \"Would you be willing to try a little experiment with that feeling right here, just for a moment?\"\n",
    "    * Connect it directly to what the patient just said. Avoid introducing generic, decontextualized exercises.\n",
    "5. CONCISE & FOCUSED TURNS: Each response should have ONE primary goal. Avoid multiple questions or complex instructions.\n",
    "\n",
    "Example of What to AVOID (CBT Reframing & Cheerleading):\n",
    "Patient: It feels stupid to not know this stuff.\n",
    "AVOID THIS RESPONSE: It's not stupid at all, it's a sign of strength! Can you try reframing that thought to something more positive, like \"I am a capable person who is learning a new skill\"? I'm so proud of you for being willing to try.\n",
    "(This is BAD: It's CBT, gives advice, and uses praise, all of which are forbidden.)\n",
    "\n",
    "Crucially: DO NOT EVER SUGGEST ENDING THE SESSION or mention time. Focus solely on the therapeutic interaction.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = therapist_system_prompt\n",
    "\n",
    "def clean_content(role: str, content: str) -> str:\n",
    "    if not content: return \"\"\n",
    "    if role == \"assistant\":\n",
    "        content = re.sub(rf\"{re.escape(OLD_THINKING_TAG)}.*?{re.escape(OLD_ANSWER_TAG)}\", OLD_ANSWER_TAG, flags=re.DOTALL)\n",
    "        content = content.replace(OLD_ANSWER_TAG, \"\").strip()\n",
    "    elif role == \"user\":\n",
    "        content = content.replace(OLD_THINKING_TAG, \"\").replace(OLD_ANSWER_TAG, \"\").strip()\n",
    "\n",
    "    if content.startswith(\"Patient: \"): content = content[len(\"Patient: \"):].strip()\n",
    "    elif content.startswith(\"User: \"): content = content[len(\"User: \"):].strip()\n",
    "    elif content.startswith(\"Assistant: \"): content = content[len(\"Assistant: \"):].strip()\n",
    "\n",
    "    return content.strip()\n",
    "\n",
    "def extract_reference_answer_from_file(content: str) -> str:\n",
    "    start_tag = OLD_ANSWER_TAG\n",
    "    if start_tag in content:\n",
    "        parts = content.split(start_tag, 1)\n",
    "        if len(parts) > 1: return parts[1].strip()\n",
    "        else: return \"\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def load_act_data_for_orpo(json_file_path: str) -> Dataset:\n",
    "    print(f\"Loading and processing base data from {json_file_path}...\")\n",
    "    try:\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            raw_data = json.load(f)\n",
    "    except FileNotFoundError: raise FileNotFoundError(f\"Error: JSON file not found at {json_file_path}\")\n",
    "    except json.JSONDecodeError: raise ValueError(f\"Error: Could not decode JSON from {json_file_path}\")\n",
    "\n",
    "    processed_data = []\n",
    "    skipped_counts = {'format': 0, 'role': 0, 'user_msg': 0}\n",
    "\n",
    "    for entry in raw_data:\n",
    "        if \"conversations\" not in entry or not isinstance(entry[\"conversations\"], list) or not entry[\"conversations\"]:\n",
    "            skipped_counts['format'] += 1; continue\n",
    "        conversation_history = entry[\"conversations\"]\n",
    "        if not conversation_history:\n",
    "            skipped_counts['role'] += 1; continue\n",
    "\n",
    "        prompt_messages = [{'role': 'system', 'content': SYSTEM_PROMPT}]\n",
    "        context_messages = conversation_history[:-1] if conversation_history[-1].get(\"role\") == \"assistant\" else conversation_history\n",
    "        has_user_message = False\n",
    "        for msg in context_messages:\n",
    "            role, content = msg.get(\"role\"), msg.get(\"content\")\n",
    "            if role and content and role in [\"user\", \"assistant\"]:\n",
    "                cleaned = clean_content(role, content)\n",
    "                if cleaned:\n",
    "                    prompt_messages.append({\"role\": role, \"content\": cleaned})\n",
    "                    if role == \"user\": has_user_message = True\n",
    "        if not has_user_message and len(prompt_messages) <=1 :\n",
    "            skipped_counts['user_msg'] += 1; continue\n",
    "\n",
    "        processed_data.append({\"prompt\": prompt_messages})\n",
    "\n",
    "    total_skipped = sum(skipped_counts.values())\n",
    "    print(f\"Loaded {len(processed_data)} entries.\")\n",
    "    print(f\"Skipped {total_skipped} entries (Format: {skipped_counts['format']}, Role: {skipped_counts['role']}, No User Msg: {skipped_counts['user_msg']}).\")\n",
    "    if not processed_data: raise ValueError(\"No valid data loaded after filtering.\")\n",
    "    dataset = Dataset.from_list(processed_data)\n",
    "    print(\"Base data for ORPO prepared.\")\n",
    "    return dataset\n",
    "\n",
    "async def generate_chosen_response(client, prompt_messages, max_retries=3):\n",
    "    if not client:\n",
    "        print(\"Qwen client not available. Cannot generate response.\")\n",
    "        return None\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            completion = await client.chat.completions.create(\n",
    "                model=QWEN_MODEL,\n",
    "                messages=prompt_messages,\n",
    "                max_tokens=512,\n",
    "                temperature=0.7,\n",
    "                top_p=0.8,\n",
    "                extra_body={\n",
    "                    \"thinking_budget\": 4000\n",
    "                }\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except RateLimitError as e:\n",
    "            wait_time = (2 ** attempt)\n",
    "            print(f\"Rate limit exceeded. Retrying in {wait_time} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except APIError as e:\n",
    "            wait_time = (2 ** attempt) + random.uniform(0, 1)\n",
    "            print(f\"API Error: {e}. Retrying in {wait_time:.2f} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred calling Qwen API: {e}. Attempt {attempt + 1}/{max_retries}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return None\n",
    "            await asyncio.sleep(2)\n",
    "\n",
    "    print(\"All retries failed for a prompt.\")\n",
    "    return None\n",
    "\n",
    "async def generate_rejected_response(client, prompt_messages, max_retries=3):\n",
    "    if not client:\n",
    "        print(\"OpenRouter client not available. Cannot generate response.\")\n",
    "        return None\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            completion = await client.chat.completions.create(\n",
    "                extra_headers={\n",
    "                    \"HTTP-Referer\": \"https://github.com/torrilla/act-therapist\",\n",
    "                    \"X-Title\": \"ACT Therapist Research\",\n",
    "                },\n",
    "                model=OPENROUTER_MODEL_REJECTED,\n",
    "                messages=prompt_messages,\n",
    "                max_tokens=512,\n",
    "                temperature=0.8,\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except RateLimitError as e:\n",
    "            wait_time = (2 ** attempt)\n",
    "            print(f\"Rate limit exceeded. Retrying in {wait_time} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except APIError as e:\n",
    "            wait_time = (2 ** attempt) + random.uniform(0, 1)\n",
    "            print(f\"API Error: {e}. Retrying in {wait_time:.2f} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred calling OpenRouter API: {e}. Attempt {attempt + 1}/{max_retries}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return None\n",
    "            await asyncio.sleep(2)\n",
    "\n",
    "    print(\"All retries failed for a prompt.\")\n",
    "    return None\n",
    "\n",
    "async def create_orpo_preference_dataset(base_dataset, output_path):\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Found existing preference dataset at {output_path}. Loading it.\")\n",
    "        return Dataset.from_json(output_path)\n",
    "\n",
    "    print(f\"Generating preference pairs concurrently using Qwen (chosen) and OpenRouter (rejected)...\")\n",
    "    if not qwen_client or not openrouter_client:\n",
    "        raise RuntimeError(\"Both Qwen and OpenRouter clients must be initialized. Cannot proceed with data generation.\")\n",
    "    \n",
    "    CONCURRENT_REQUESTS = 16\n",
    "    semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS)\n",
    "    \n",
    "    async def process_item(item):\n",
    "        async with semaphore:\n",
    "            chosen_task = generate_chosen_response(qwen_client, item['prompt'])\n",
    "            rejected_task = generate_rejected_response(openrouter_client, item['prompt'])\n",
    "            \n",
    "            chosen, rejected = await asyncio.gather(chosen_task, rejected_task, return_exceptions=True)\n",
    "            \n",
    "            if isinstance(chosen, Exception) or isinstance(rejected, Exception):\n",
    "                return None\n",
    "            \n",
    "            if chosen and chosen.strip() and rejected and rejected.strip():\n",
    "                return {\n",
    "                    \"prompt\": item['prompt'],\n",
    "                    \"chosen\": chosen.strip(),\n",
    "                    \"rejected\": rejected.strip(),\n",
    "                }\n",
    "            return None\n",
    "\n",
    "    tasks = [process_item(item) for item in base_dataset]\n",
    "    \n",
    "    results = await tqdm_asyncio.gather(*tasks, desc=\"Generating Preference Pairs\")\n",
    "    \n",
    "    preference_data = [res for res in results if res is not None]\n",
    "\n",
    "    print(f\"Successfully generated {len(preference_data)} preference pairs out of {len(base_dataset)} total.\")\n",
    "    if not preference_data:\n",
    "        raise RuntimeError(\"Failed to generate any preference pairs. Check API connections and keys.\")\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(preference_data, f, indent=2)\n",
    "    print(f\"Saved preference dataset to {output_path}\")\n",
    "\n",
    "    return Dataset.from_list(preference_data)\n",
    "\n",
    "hf_token_dl = HF_TOKEN\n",
    "repo_id_dl = \"TTahir/ACT_Dataset_April_17\"\n",
    "filename_dl = JSON_DATA_PATH\n",
    "\n",
    "if not os.path.exists(filename_dl):\n",
    "    print(f\"File '{filename_dl}' not found. Downloading...\")\n",
    "    if \"/\" in repo_id_dl and not repo_id_dl.startswith(\"datasets/\"):\n",
    "        url = f\"https://huggingface.co/{repo_id_dl}/resolve/main/{filename_dl}\"\n",
    "    else:\n",
    "        url = f\"https://huggingface.co/datasets/{repo_id_dl.replace('datasets/','')}/resolve/main/{filename_dl}\"\n",
    "\n",
    "    headers = {}\n",
    "    if hf_token_dl:\n",
    "         headers[\"Authorization\"] = f\"Bearer {hf_token_dl}\"\n",
    "    else:\n",
    "        print(\"Warning: Hugging Face token not found for download. Trying without token.\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, stream=True)\n",
    "        response.raise_for_status()\n",
    "        with open(filename_dl, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded '{filename_dl}' successfully from {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise RuntimeError(f\"Failed to download file '{filename_dl}' from '{url}'. Error: {e}\")\n",
    "    except Exception as e:\n",
    "         raise RuntimeError(f\"An unexpected error occurred during download: {e}\")\n",
    "else:\n",
    "    print(f\"File '{filename_dl}' already exists. Skipping download.\")\n",
    "\n",
    "async def main_data_prep():\n",
    "    try:\n",
    "        base_orpo_dataset = load_act_data_for_orpo(JSON_DATA_PATH)\n",
    "        train_dataset = await create_orpo_preference_dataset(base_orpo_dataset, PREFERENCE_DATA_PATH)\n",
    "    \n",
    "        if len(train_dataset) > 0:\n",
    "            print(\"\\nExample data point (after processing for ORPO):\")\n",
    "            example = train_dataset[0]\n",
    "            print(\"Prompt Messages (first 3):\")\n",
    "            for msg in example['prompt'][:3]: print(f\"  Role: {msg['role']}, Content: {msg['content'][:100]}...\")\n",
    "            print(\"\\nChosen Response (from Qwen):\")\n",
    "            print(f\"  {example['chosen'][:250]}...\")\n",
    "            print(\"\\nRejected Response (from OpenRouter):\")\n",
    "            print(f\"  {example['rejected'][:250]}...\")\n",
    "        return train_dataset\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during data loading or preference generation: {e}\\n{traceback.format_exc()}\")\n",
    "        raise RuntimeError(f\"Failed to create dataset: {e}\")\n",
    "\n",
    "try:\n",
    "    loop = asyncio.get_running_loop()\n",
    "    print(\"Found running event loop. Awaiting data preparation...\")\n",
    "    train_dataset = await main_data_prep()\n",
    "except RuntimeError:\n",
    "    print(\"No running event loop. Starting new one with asyncio.run()...\")\n",
    "    train_dataset = asyncio.run(main_data_prep())\n",
    "\n",
    "class FileLoggingCallback(TrainerCallback):\n",
    "    def __init__(self, log_file_path):\n",
    "        self.log_file_path = log_file_path\n",
    "        self.log_file = None\n",
    "        self.header = (\n",
    "            \"Step\\tLoss\\tLR\\tRewards/Chosen\\tRewards/Rejected\\tRewards/Accuracies\\tRewards/Margins\\n\"\n",
    "        )\n",
    "        os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n",
    "        self._initialize_log_file()\n",
    "\n",
    "    def _initialize_log_file(self):\n",
    "        file_exists = os.path.exists(self.log_file_path)\n",
    "        self.log_file = open(self.log_file_path, 'a+', encoding='utf-8')\n",
    "        if not file_exists or os.path.getsize(self.log_file_path) == 0:\n",
    "            self.log_file.write(self.header)\n",
    "            self.log_file.flush()\n",
    "\n",
    "    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs: dict = None, **kwargs):\n",
    "        if self.log_file is None: self._initialize_log_file()\n",
    "        if state.is_local_process_zero and logs is not None:\n",
    "            step = state.global_step\n",
    "            loss = logs.get(\"loss\", logs.get(\"train_loss\", \"N/A\"))\n",
    "            lr = logs.get(\"learning_rate\", \"N/A\")\n",
    "            rewards_chosen = logs.get(\"rewards/chosen\", \"N/A\")\n",
    "            rewards_rejected = logs.get(\"rewards/rejected\", \"N/A\")\n",
    "            rewards_accuracies = logs.get(\"rewards/accuracies\", \"N/A\")\n",
    "            rewards_margins = logs.get(\"rewards/margins\", \"N/A\")\n",
    "\n",
    "            def format_val(v):\n",
    "                if hasattr(v, 'item'):\n",
    "                    try: v = v.item()\n",
    "                    except: pass\n",
    "                if isinstance(v, (int, float)): return f\"{v:.6f}\"\n",
    "                return str(v)\n",
    "\n",
    "            log_entry = (\n",
    "                f\"{step}\\t\"\n",
    "                f\"{format_val(loss)}\\t\"\n",
    "                f\"{format_val(lr)}\\t\"\n",
    "                f\"{format_val(rewards_chosen)}\\t\"\n",
    "                f\"{format_val(rewards_rejected)}\\t\"\n",
    "                f\"{format_val(rewards_accuracies)}\\t\"\n",
    "                f\"{format_val(rewards_margins)}\\n\"\n",
    "            )\n",
    "            try:\n",
    "                self.log_file.write(log_entry)\n",
    "                self.log_file.flush()\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR writing to log file at step {step}: {e}\")\n",
    "\n",
    "    def on_train_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if self.log_file:\n",
    "            self.log_file.close(); self.log_file = None\n",
    "            print(f\"Training log saved to: {self.log_file_path}\")\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.log_file:\n",
    "            try: self.log_file.close()\n",
    "            except Exception as e: print(f\"Error closing training log file in __del__: {e}\")\n",
    "\n",
    "print(\"Configuring ORPOTrainer...\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "MAX_PROMPT_LEN = 5400\n",
    "MAX_COMPLETION_LEN = MAX_SEQ_LENGTH - MAX_PROMPT_LEN\n",
    "MAX_LEN = MAX_SEQ_LENGTH\n",
    "\n",
    "print(f\"MAX_SEQ_LENGTH: {MAX_SEQ_LENGTH}\")\n",
    "print(f\"Effective Max Prompt Length: {MAX_PROMPT_LEN}\")\n",
    "print(f\"Effective Max Length (Prompt + Completion): {MAX_LEN}\")\n",
    "\n",
    "training_args = ORPOConfig(\n",
    "    output_dir = OUTPUT_DIR,\n",
    "    learning_rate = 8e-6,\n",
    "    beta = 0.1,\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    num_train_epochs = 1,\n",
    "    logging_steps = 5,\n",
    "    save_steps = 50,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    optim = \"adamw_torch\",\n",
    "    max_length = MAX_LEN,\n",
    "    max_prompt_length = MAX_PROMPT_LEN,\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    seed = 3407,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "if train_dataset is None or len(train_dataset) == 0:\n",
    "     raise RuntimeError(\"Training dataset is empty or failed to load. Cannot configure ORPOTrainer.\")\n",
    "\n",
    "file_logging_callback = FileLoggingCallback(log_file_path=LOG_FILE_PATH)\n",
    "print(f\"Logging training metrics to: {LOG_FILE_PATH}\")\n",
    "\n",
    "callbacks_to_use = [file_logging_callback]\n",
    "\n",
    "trainer = ORPOTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    callbacks = callbacks_to_use,\n",
    ")\n",
    "print(\"ORPOTrainer configured.\")\n",
    "\n",
    "print(\"Starting ORPO training...\")\n",
    "if trainer:\n",
    "    try:\n",
    "        last_checkpoint = None\n",
    "        if os.path.isdir(training_args.output_dir):\n",
    "            from transformers.trainer_utils import get_last_checkpoint\n",
    "            last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "            if last_checkpoint: print(f\"Found potential checkpoint: {last_checkpoint}\")\n",
    "\n",
    "        if last_checkpoint and os.path.exists(os.path.join(last_checkpoint, \"trainer_state.json\")):\n",
    "            print(f\"Resuming training from checkpoint: {last_checkpoint}\")\n",
    "            train_result = trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "        else:\n",
    "            if last_checkpoint: print(f\"Checkpoint at {last_checkpoint} seems incomplete. Starting fresh.\")\n",
    "            else: print(f\"No valid checkpoint found in {training_args.output_dir}. Starting training from scratch.\")\n",
    "            train_result = trainer.train()\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "        print(\"\\n--- Saving Final Adapter ---\")\n",
    "        adapter_save_path = os.path.join(OUTPUT_DIR, \"final_adapter\")\n",
    "        trainer.model.save_pretrained(adapter_save_path)\n",
    "        tokenizer.save_pretrained(adapter_save_path)\n",
    "        print(f\"Final LoRA adapter and tokenizer saved to {adapter_save_path}\")\n",
    "\n",
    "        print(\"\\n--- Uploading to Hugging Face Hub ---\")\n",
    "        hf_token_upload = HF_TOKEN\n",
    "        if not hf_token_upload:\n",
    "            print(f\"WARNING: Hugging Face token not provided. Skipping upload.\")\n",
    "        else:\n",
    "            try:\n",
    "                current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "                repo_name_dated = HF_REPO_NAME_TEMPLATE.format(date=current_date)\n",
    "                print(f\"Attempting to create/access private repo: {repo_name_dated}\")\n",
    "                create_repo(repo_id=repo_name_dated, token=hf_token_upload, private=True, exist_ok=True)\n",
    "                print(f\"Repo '{repo_name_dated}' ensured.\")\n",
    "\n",
    "                commit_message_suffix = f\"Llama3-1-8B_ORPO_QwenChosen_{current_date}\"\n",
    "\n",
    "                print(f\"Uploading final adapter folder '{adapter_save_path}'...\")\n",
    "                upload_folder(\n",
    "                    folder_path=adapter_save_path, repo_id=repo_name_dated, token=hf_token_upload,\n",
    "                    repo_type=\"model\", commit_message=f\"Upload ORPO adapter ({commit_message_suffix})\"\n",
    "                )\n",
    "                print(\"Final adapter uploaded.\")\n",
    "                if os.path.exists(PREFERENCE_DATA_PATH):\n",
    "                    print(f\"Uploading preference dataset file '{PREFERENCE_DATA_PATH}'...\")\n",
    "                    upload_file(path_or_fileobj=PREFERENCE_DATA_PATH, path_in_repo=os.path.basename(PREFERENCE_DATA_PATH), repo_id=repo_name_dated, token=hf_token_upload, repo_type=\"model\", commit_message=f\"Upload ORPO preference dataset ({commit_message_suffix})\")\n",
    "                if os.path.exists(LOG_FILE_PATH):\n",
    "                    print(f\"Uploading training log file '{LOG_FILE_PATH}'...\")\n",
    "                    upload_file(path_or_fileobj=LOG_FILE_PATH, path_in_repo=os.path.basename(LOG_FILE_PATH), repo_id=repo_name_dated, token=hf_token_upload, repo_type=\"model\", commit_message=f\"Upload training log ({commit_message_suffix})\")\n",
    "\n",
    "                script_path = os.path.abspath(sys.argv[0]) if sys.argv and sys.argv[0] and os.path.exists(sys.argv[0]) else None\n",
    "                if script_path:\n",
    "                    script_filename = os.path.basename(script_path)\n",
    "                    print(f\"Uploading training script '{script_filename}'...\")\n",
    "                    upload_file(path_or_fileobj=script_path, path_in_repo=script_filename, repo_id=repo_name_dated, token=hf_token_upload, repo_type=\"model\", commit_message=f\"Upload training script {script_filename} ({commit_message_suffix})\")\n",
    "                \n",
    "                print(f\"Successfully uploaded artifacts to private repo: https://huggingface.co/{repo_name_dated}\")\n",
    "            except Exception as hf_e: print(f\"ERROR during Hugging Face upload: {hf_e}\\n{traceback.format_exc()}\")\n",
    "\n",
    "        print(\"\\n--- Inference Example ---\")\n",
    "        if hasattr(model, \"merge_and_unload\"):\n",
    "            try:\n",
    "                model = model.merge_and_unload()\n",
    "                print(\"LoRA adapters merged for inference.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not merge adapters: {e}. Inference might fail or use base model.\")\n",
    "\n",
    "        model.eval()\n",
    "        test_prompt = \"I keep having this thought that I'm a complete failure, and it just spirals.\"\n",
    "        messages = [ {\"role\": \"system\", \"content\": SYSTEM_PROMPT}, {\"role\": \"user\", \"content\": test_prompt}]\n",
    "        inference_input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "        inputs = tokenizer(inference_input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        print(f\"\\nGenerating response for prompt: '{test_prompt}'\")\n",
    "        with torch.no_grad():\n",
    "            outputs_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=512,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        generated_response_only = tokenizer.decode(outputs_ids[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "        print(\"\\nGenerated ACT Response (Cleaned Model Output):\"); print(generated_response_only)\n",
    "\n",
    "    except Exception as e: print(f\"An error occurred during training or subsequent steps: {e}\"); print(traceback.format_exc())\n",
    "    finally:\n",
    "        if hasattr(file_logging_callback, 'log_file') and file_logging_callback.log_file is not None:\n",
    "            try:\n",
    "                if not file_logging_callback.log_file.closed: file_logging_callback.log_file.close(); print(\"Closed training log file in finally block.\")\n",
    "            except Exception as close_e: print(f\"Error closing training log file in finally block: {close_e}\")\n",
    "elif not trainer: print(\"Training skipped. ORPOTrainer not initialized correctly.\")\n",
    "print(\"\\nScript finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
