{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9563374a-57e2-4b4f-a49e-9da14f0b1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all folders in working directory, leave files alone\n",
    "!find . -mindepth 1 -maxdepth 1 -type d -exec rm -r {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dab48f-5b86-4d48-ba01-dc5416adba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unsloth\n",
    "!pip install instructor\n",
    "!pip install openai\n",
    "!pip install pydantic\n",
    "!pip install dotenv\n",
    "!pip install huggingface_hub\n",
    "!python -m pip install --upgrade typing_extensions\n",
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ebc31-9312-4d42-be5a-dd9ffbe85647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 08-20 22:25:12 [__init__.py:241] Automatically detected platform cuda.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "OpenRouter API key provided. Initializing ASYNC client for generating 'rejected' responses...\n",
      "Async OpenRouter client initialized successfully.\n",
      "Qwen API key provided. Initializing ASYNC client for generating 'chosen' responses...\n",
      "Async Qwen client initialized successfully.\n",
      "Loading base model and tokenizer...\n",
      "==((====))==  Unsloth 2025.8.9: Fast Llama patching. Transformers: 4.55.2. vLLM: 0.10.1.\n",
      "   \\\\   /|    NVIDIA RTX A5000. Num GPUs = 1. Max memory: 23.573 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309a017a234c4179a4b90bb583d08d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea806e2b3a948229a9f6d5dc9cead2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8fd5f511ab485fb92eece7d6dd4e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743ed24009b24dd3a17853f8c8b41bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f829b8f54f4c24b40f54e13dcdfa01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35653e2670d440bd9a87fe85eafcf094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f105c6af95a4b5ba29094f858e9a45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f949d35aec4e6a87656cc6379d663e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca49e166c6d4fa9ad10667d2f3e1f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8432371eea0e434394166673fc309322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PEFT (LoRA)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.9 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and LoRA setup complete.\n",
      "File 'combined_unsloth_dataset.json' already exists. Skipping download.\n",
      "Found running event loop. Awaiting data preparation...\n",
      "Loading and processing base data from combined_unsloth_dataset.json...\n",
      "Loaded 1250 entries.\n",
      "Skipped 0 entries (Format: 0, Role: 0, No User Msg: 0).\n",
      "Base data for ORPO prepared.\n",
      "Generating preference pairs concurrently using Qwen (chosen) and OpenRouter (rejected)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Preference Pairs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [29:08<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated 1250 preference pairs out of 1250 total.\n",
      "Saved preference dataset to orpo_preference_dataset.json\n",
      "\n",
      "Example data point (after processing for ORPO):\n",
      "Prompt Messages (first 3):\n",
      "  Role: system, Content: CRITICAL OUTPUT FORMAT: You MUST structure EVERY response with a thinking section followed by an ans...\n",
      "  Role: user, Content: I don't even know where to start. I've been feeling so overwhelmed lately. It's like everything sets...\n",
      "\n",
      "Chosen Response (from Qwen):\n",
      "  Thinking:\n",
      "Patient expresses intense anger and overwhelm, particularly around the new job, with a sense of helplessness (\"don't even know where to start\"). Core emotion is anger layered with exhaustion. Goal: Explore the tangible context of \"everythin...\n",
      "\n",
      "Rejected Response (from OpenRouter):\n",
      "  Thinking:\n",
      "You express a core emotion of overwhelm and anger, which may be linked to your new job. I want to explore the tangible context of \"overwhelmed\" and identify potential unworkable strategies that might be contributing to your anger.\n",
      "\n",
      "Answer:\n",
      "...\n",
      "Configuring ORPOTrainer...\n",
      "MAX_SEQ_LENGTH: 9000\n",
      "Effective Max Prompt Length: 5400\n",
      "Effective Max Length (Prompt + Completion): 9000\n",
      "Logging training metrics to: act-therapist-orpo-llama31-3b/training_log.tsv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb5aa1fcc4a429ab35c2d43fac9577a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78064b877c2648f494b2f8657acc2805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d0ce07a0d74b7c9df3e26f139e35e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORPOTrainer configured.\n",
      "Starting ORPO training...\n",
      "No valid checkpoint found in act-therapist-orpo-llama31-3b. Starting training from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,250 | Num Epochs = 1 | Total steps = 157\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 04:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>rewards / chosen</th>\n",
       "      <th>rewards / rejected</th>\n",
       "      <th>rewards / accuracies</th>\n",
       "      <th>rewards / margins</th>\n",
       "      <th>logps / rejected</th>\n",
       "      <th>logps / chosen</th>\n",
       "      <th>logits / rejected</th>\n",
       "      <th>logits / chosen</th>\n",
       "      <th>log_odds_ratio</th>\n",
       "      <th>log_odds_chosen</th>\n",
       "      <th>eval_logits / chosen</th>\n",
       "      <th>eval_logits / rejected</th>\n",
       "      <th>nll_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.837100</td>\n",
       "      <td>-0.357223</td>\n",
       "      <td>-0.196604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.160619</td>\n",
       "      <td>-1.966041</td>\n",
       "      <td>-3.572229</td>\n",
       "      <td>-0.874785</td>\n",
       "      <td>-0.654762</td>\n",
       "      <td>-1.916027</td>\n",
       "      <td>-1.739805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.645452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.856700</td>\n",
       "      <td>-0.358899</td>\n",
       "      <td>-0.196459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.162441</td>\n",
       "      <td>-1.964588</td>\n",
       "      <td>-3.588993</td>\n",
       "      <td>-0.873744</td>\n",
       "      <td>-0.635164</td>\n",
       "      <td>-1.923082</td>\n",
       "      <td>-1.753498</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.664363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.773300</td>\n",
       "      <td>-0.352168</td>\n",
       "      <td>-0.202979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.149189</td>\n",
       "      <td>-2.029787</td>\n",
       "      <td>-3.521678</td>\n",
       "      <td>-0.870663</td>\n",
       "      <td>-0.674012</td>\n",
       "      <td>-1.810173</td>\n",
       "      <td>-1.612161</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.592265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.765000</td>\n",
       "      <td>-0.351453</td>\n",
       "      <td>-0.206685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.144769</td>\n",
       "      <td>-2.066847</td>\n",
       "      <td>-3.514532</td>\n",
       "      <td>-1.004884</td>\n",
       "      <td>-0.683175</td>\n",
       "      <td>-1.770630</td>\n",
       "      <td>-1.563412</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.587894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.614700</td>\n",
       "      <td>-0.337151</td>\n",
       "      <td>-0.202899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.134252</td>\n",
       "      <td>-2.028987</td>\n",
       "      <td>-3.371510</td>\n",
       "      <td>-0.994564</td>\n",
       "      <td>-0.616317</td>\n",
       "      <td>-1.682375</td>\n",
       "      <td>-1.459433</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.446468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.598900</td>\n",
       "      <td>-0.334902</td>\n",
       "      <td>-0.191032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.143870</td>\n",
       "      <td>-1.910320</td>\n",
       "      <td>-3.349024</td>\n",
       "      <td>-0.875272</td>\n",
       "      <td>-0.638160</td>\n",
       "      <td>-1.777368</td>\n",
       "      <td>-1.574673</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.421178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.441000</td>\n",
       "      <td>-0.321400</td>\n",
       "      <td>-0.183955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.137445</td>\n",
       "      <td>-1.839551</td>\n",
       "      <td>-3.213996</td>\n",
       "      <td>-0.796161</td>\n",
       "      <td>-0.647011</td>\n",
       "      <td>-1.728381</td>\n",
       "      <td>-1.517227</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.268186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.418800</td>\n",
       "      <td>-0.318320</td>\n",
       "      <td>-0.175558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.142762</td>\n",
       "      <td>-1.755580</td>\n",
       "      <td>-3.183204</td>\n",
       "      <td>-0.743700</td>\n",
       "      <td>-0.616736</td>\n",
       "      <td>-1.783633</td>\n",
       "      <td>-1.586762</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.240396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.327900</td>\n",
       "      <td>-0.310911</td>\n",
       "      <td>-0.187735</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.123176</td>\n",
       "      <td>-1.877351</td>\n",
       "      <td>-3.109109</td>\n",
       "      <td>-0.898967</td>\n",
       "      <td>-0.536047</td>\n",
       "      <td>-1.611775</td>\n",
       "      <td>-1.366302</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.166764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.255500</td>\n",
       "      <td>-0.305680</td>\n",
       "      <td>-0.181667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.124013</td>\n",
       "      <td>-1.816674</td>\n",
       "      <td>-3.056803</td>\n",
       "      <td>-0.697403</td>\n",
       "      <td>-0.503317</td>\n",
       "      <td>-1.611297</td>\n",
       "      <td>-1.376715</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>3.094349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>3.138900</td>\n",
       "      <td>-0.293811</td>\n",
       "      <td>-0.171160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.122651</td>\n",
       "      <td>-1.711603</td>\n",
       "      <td>-2.938113</td>\n",
       "      <td>-0.601599</td>\n",
       "      <td>-0.510347</td>\n",
       "      <td>-1.615191</td>\n",
       "      <td>-1.378584</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.977405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.066700</td>\n",
       "      <td>-0.286846</td>\n",
       "      <td>-0.165798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.121049</td>\n",
       "      <td>-1.657980</td>\n",
       "      <td>-2.868465</td>\n",
       "      <td>-0.521419</td>\n",
       "      <td>-0.368287</td>\n",
       "      <td>-1.605957</td>\n",
       "      <td>-1.370273</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.906092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>2.989900</td>\n",
       "      <td>-0.280394</td>\n",
       "      <td>-0.177663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.102731</td>\n",
       "      <td>-1.776625</td>\n",
       "      <td>-2.803938</td>\n",
       "      <td>-0.757520</td>\n",
       "      <td>-0.452594</td>\n",
       "      <td>-1.438741</td>\n",
       "      <td>-1.155698</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.846069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.872800</td>\n",
       "      <td>-0.269831</td>\n",
       "      <td>-0.169933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.099899</td>\n",
       "      <td>-1.699325</td>\n",
       "      <td>-2.698312</td>\n",
       "      <td>-0.677873</td>\n",
       "      <td>-0.415190</td>\n",
       "      <td>-1.426892</td>\n",
       "      <td>-1.137379</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.730142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.824300</td>\n",
       "      <td>-0.267063</td>\n",
       "      <td>-0.178227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.088836</td>\n",
       "      <td>-1.782269</td>\n",
       "      <td>-2.670629</td>\n",
       "      <td>-0.681541</td>\n",
       "      <td>-0.372460</td>\n",
       "      <td>-1.332235</td>\n",
       "      <td>-1.007010</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.691046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.813000</td>\n",
       "      <td>-0.264588</td>\n",
       "      <td>-0.173229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.091358</td>\n",
       "      <td>-1.732293</td>\n",
       "      <td>-2.645877</td>\n",
       "      <td>-0.552499</td>\n",
       "      <td>-0.388887</td>\n",
       "      <td>-1.356295</td>\n",
       "      <td>-1.039226</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.677383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>2.728700</td>\n",
       "      <td>-0.258568</td>\n",
       "      <td>-0.180550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.078018</td>\n",
       "      <td>-1.805501</td>\n",
       "      <td>-2.585677</td>\n",
       "      <td>-0.522663</td>\n",
       "      <td>-0.359430</td>\n",
       "      <td>-1.241579</td>\n",
       "      <td>-0.886410</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.604529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.695100</td>\n",
       "      <td>-0.255344</td>\n",
       "      <td>-0.182432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.072912</td>\n",
       "      <td>-1.824322</td>\n",
       "      <td>-2.553440</td>\n",
       "      <td>-0.658194</td>\n",
       "      <td>-0.335522</td>\n",
       "      <td>-1.202672</td>\n",
       "      <td>-0.828065</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.574791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>2.644700</td>\n",
       "      <td>-0.251477</td>\n",
       "      <td>-0.188705</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.062772</td>\n",
       "      <td>-1.887050</td>\n",
       "      <td>-2.514770</td>\n",
       "      <td>-0.692312</td>\n",
       "      <td>-0.269161</td>\n",
       "      <td>-1.133345</td>\n",
       "      <td>-0.714175</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.531364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.606900</td>\n",
       "      <td>-0.247381</td>\n",
       "      <td>-0.183773</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.063608</td>\n",
       "      <td>-1.837727</td>\n",
       "      <td>-2.473805</td>\n",
       "      <td>-0.463884</td>\n",
       "      <td>-0.346172</td>\n",
       "      <td>-1.136206</td>\n",
       "      <td>-0.725245</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.493267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>2.601800</td>\n",
       "      <td>-0.247973</td>\n",
       "      <td>-0.186823</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.061150</td>\n",
       "      <td>-1.868228</td>\n",
       "      <td>-2.479729</td>\n",
       "      <td>-0.421917</td>\n",
       "      <td>-0.270276</td>\n",
       "      <td>-1.115465</td>\n",
       "      <td>-0.697127</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.490222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.561800</td>\n",
       "      <td>-0.244183</td>\n",
       "      <td>-0.193987</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.050196</td>\n",
       "      <td>-1.939870</td>\n",
       "      <td>-2.441830</td>\n",
       "      <td>-0.499026</td>\n",
       "      <td>-0.184834</td>\n",
       "      <td>-1.036101</td>\n",
       "      <td>-0.571679</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.458191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2.557700</td>\n",
       "      <td>-0.243829</td>\n",
       "      <td>-0.194307</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>-0.049522</td>\n",
       "      <td>-1.943071</td>\n",
       "      <td>-2.438288</td>\n",
       "      <td>-0.449583</td>\n",
       "      <td>-0.187927</td>\n",
       "      <td>-1.024462</td>\n",
       "      <td>-0.560089</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.455292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.552100</td>\n",
       "      <td>-0.243451</td>\n",
       "      <td>-0.197298</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>-0.046153</td>\n",
       "      <td>-1.972980</td>\n",
       "      <td>-2.434514</td>\n",
       "      <td>-0.616327</td>\n",
       "      <td>-0.240476</td>\n",
       "      <td>-1.002517</td>\n",
       "      <td>-0.523364</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.451848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.540400</td>\n",
       "      <td>-0.242013</td>\n",
       "      <td>-0.192207</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.049807</td>\n",
       "      <td>-1.922065</td>\n",
       "      <td>-2.420134</td>\n",
       "      <td>-0.344222</td>\n",
       "      <td>-0.166764</td>\n",
       "      <td>-1.028948</td>\n",
       "      <td>-0.565238</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.437528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.510300</td>\n",
       "      <td>-0.240730</td>\n",
       "      <td>-0.200421</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>-0.040309</td>\n",
       "      <td>-2.004210</td>\n",
       "      <td>-2.407298</td>\n",
       "      <td>-0.569663</td>\n",
       "      <td>-0.171213</td>\n",
       "      <td>-0.956715</td>\n",
       "      <td>-0.455770</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.414613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>2.597600</td>\n",
       "      <td>-0.247624</td>\n",
       "      <td>-0.199302</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.048322</td>\n",
       "      <td>-1.993020</td>\n",
       "      <td>-2.476237</td>\n",
       "      <td>-0.392570</td>\n",
       "      <td>-0.151537</td>\n",
       "      <td>-1.017422</td>\n",
       "      <td>-0.544331</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.495833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.526700</td>\n",
       "      <td>-0.241678</td>\n",
       "      <td>-0.199001</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>-0.042677</td>\n",
       "      <td>-1.990006</td>\n",
       "      <td>-2.416781</td>\n",
       "      <td>-0.459986</td>\n",
       "      <td>-0.152056</td>\n",
       "      <td>-0.978812</td>\n",
       "      <td>-0.483734</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.428778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2.548500</td>\n",
       "      <td>-0.243836</td>\n",
       "      <td>-0.208442</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.035393</td>\n",
       "      <td>-2.084424</td>\n",
       "      <td>-2.438357</td>\n",
       "      <td>-0.545103</td>\n",
       "      <td>-0.139132</td>\n",
       "      <td>-0.936677</td>\n",
       "      <td>-0.402492</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.454866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.506700</td>\n",
       "      <td>-0.240083</td>\n",
       "      <td>-0.209882</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>-0.030201</td>\n",
       "      <td>-2.098822</td>\n",
       "      <td>-2.400827</td>\n",
       "      <td>-0.553539</td>\n",
       "      <td>-0.125325</td>\n",
       "      <td>-0.908485</td>\n",
       "      <td>-0.345381</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.415835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>2.506100</td>\n",
       "      <td>-0.239782</td>\n",
       "      <td>-0.204058</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.035724</td>\n",
       "      <td>-2.040576</td>\n",
       "      <td>-2.397820</td>\n",
       "      <td>-0.507303</td>\n",
       "      <td>-0.197574</td>\n",
       "      <td>-0.923151</td>\n",
       "      <td>-0.402767</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>2.413745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training log saved to: act-therapist-orpo-llama31-3b/training_log.tsv\n",
      "Training finished!\n",
      "\n",
      "--- Saving Final Adapter ---\n",
      "Final LoRA adapter and tokenizer saved to act-therapist-orpo-llama31-3b/final_adapter\n",
      "\n",
      "--- Uploading to Hugging Face Hub ---\n",
      "Attempting to create/access private repo: TTahir/act-therapist-orpo-llama31-3b-2025-08-20\n",
      "Repo 'TTahir/act-therapist-orpo-llama31-3b-2025-08-20' ensured.\n",
      "Uploading final adapter folder 'act-therapist-orpo-llama31-3b/final_adapter'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4143cc30564e048c3d77d53e15452f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8b0bc024614a98ad4b36ede3b5cfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38995e2e334544028921a21a448714e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...a31-3b/final_adapter/tokenizer.json: 100%|##########| 17.2MB / 17.2MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c7655a7e5040cd929bb4665d6db1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...l_adapter/adapter_model.safetensors:   0%|          | 46.4kB /  389MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final adapter uploaded.\n",
      "Uploading preference dataset file 'orpo_preference_dataset.json'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec3e33e0b1e4fe0a36b2db58f4cca9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b806044ef043feb35ef233c3cad7de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f861f1df4c3482baae7de0e09d99efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  orpo_preference_dataset.json          :  84%|########4 | 16.1MB / 19.1MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading training log file 'act-therapist-orpo-llama31-3b/training_log.tsv'...\n",
      "Uploading training script 'ipykernel_launcher.py'...\n",
      "Successfully uploaded artifacts to private repo: https://huggingface.co/TTahir/act-therapist-orpo-llama31-3b-2025-08-20\n",
      "\n",
      "--- Inference Example ---\n",
      "LoRA adapters merged for inference.\n",
      "\n",
      "Generating response for prompt: 'I keep having this thought that I'm a complete failure, and it just spirals.'\n",
      "\n",
      "Generated ACT Response (Cleaned Model Output):\n",
      "Thinking:\n",
      "Patient expresses core emotion: shame. Identified theme/contradiction/unexplored area: the automatic association of \"failure\" with the thought, which likely fuels the spiral. Goal: Introduce willingness as an alternative to struggle, specifically by exploring the value behind this thought.\n",
      "\n",
      "Answer:\n",
      "Can you tell me what's important to you about being someone who isn't a \"failure\" â€“ what matters most to you about that value?\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from huggingface_hub import HfApi, create_repo, upload_folder, upload_file\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI, RateLimitError, APIError\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import random\n",
    "\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from trl import ORPOConfig, ORPOTrainer\n",
    "from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "MAX_SEQ_LENGTH = 9000\n",
    "LORA_RANK = 64\n",
    "JSON_DATA_PATH = \"combined_unsloth_dataset.json\"\n",
    "PREFERENCE_DATA_PATH = \"orpo_preference_dataset.json\"\n",
    "\n",
    "OPENROUTER_API_KEY = \"\"\n",
    "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "OPENROUTER_MODEL_REJECTED = \"meta-llama/llama-3.2-3b-instruct\"\n",
    "\n",
    "QWEN_API_KEY = \"\"\n",
    "QWEN_BASE_URL = \"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    "QWEN_MODEL = \"qwen3-235b-a22b-thinking-2507\"\n",
    "\n",
    "HF_USERNAME = \"TTahir\"\n",
    "HF_REPO_NAME_TEMPLATE = f\"{HF_USERNAME}/act-therapist-orpo-llama31-3b-{{date}}\"\n",
    "HF_TOKEN = \"\"\n",
    "\n",
    "KEYWORD_THINKING = \"Thinking:\"\n",
    "KEYWORD_ANSWER = \"Answer:\"\n",
    "\n",
    "OLD_THINKING_TAG = \"<|thinking|>\"\n",
    "OLD_ANSWER_TAG = \"<|answer|>\"\n",
    "\n",
    "OUTPUT_DIR = \"act-therapist-orpo-llama31-3b\"\n",
    "LOG_FILE_PATH = os.path.join(OUTPUT_DIR, \"training_log.tsv\")\n",
    "\n",
    "openrouter_client = None\n",
    "if OPENROUTER_API_KEY and OPENROUTER_BASE_URL:\n",
    "    print(\"OpenRouter API key provided. Initializing ASYNC client for generating 'rejected' responses...\")\n",
    "    try:\n",
    "        openrouter_client = AsyncOpenAI(\n",
    "            base_url=OPENROUTER_BASE_URL,\n",
    "            api_key=OPENROUTER_API_KEY,\n",
    "        )\n",
    "        print(\"Async OpenRouter client initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Error initializing Async OpenRouter client: {e}. Setting client to None.\")\n",
    "        openrouter_client = None\n",
    "else:\n",
    "    print(\"OpenRouter API key or base URL missing. Cannot generate rejected responses for ORPO.\")\n",
    "    openrouter_client = None\n",
    "\n",
    "qwen_client = None\n",
    "if QWEN_API_KEY and QWEN_BASE_URL:\n",
    "    print(\"Qwen API key provided. Initializing ASYNC client for generating 'chosen' responses...\")\n",
    "    try:\n",
    "        qwen_client = AsyncOpenAI(\n",
    "            base_url=QWEN_BASE_URL,\n",
    "            api_key=QWEN_API_KEY,\n",
    "        )\n",
    "        print(\"Async Qwen client initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Error initializing Async Qwen client: {e}. Setting client to None.\")\n",
    "        qwen_client = None\n",
    "else:\n",
    "    print(\"Qwen API key or base URL missing. Cannot generate chosen responses for ORPO.\")\n",
    "    qwen_client = None\n",
    "\n",
    "print(\"Loading base model and tokenizer...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    load_in_4bit=False,\n",
    "    fast_inference=False,\n",
    "    max_lora_rank=LORA_RANK*2,\n",
    "    gpu_memory_utilization = 0.9\n",
    ")\n",
    "assert model is not None and tokenizer is not None, \"Model or tokenizer failed to load.\"\n",
    "\n",
    "print(\"Applying PEFT (LoRA)...\")\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=LORA_RANK,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=LORA_RANK,\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    ")\n",
    "print(\"Model and LoRA setup complete.\")\n",
    "\n",
    "therapist_system_prompt = f\"\"\"CRITICAL OUTPUT FORMAT: You MUST structure EVERY response with a thinking section followed by an answer section, using these exact prefixes on their own lines:\n",
    "{KEYWORD_THINKING}\n",
    "Your concise reasoning. First, BRIEFLY acknowledge the patient's core emotion if intense. Second, identify ONE specific theme, contradiction, or unexplored area from the patient's last statement. Third, state your GOAL for the {KEYWORD_ANSWER}. Your goal must align with the ACT hexaflex and evolve throughout the session.\n",
    "* Early Goals (Exploration): \"explore the tangible context of 'stuck'\", \"probe the function of this avoidance behavior\".\n",
    "* Pivoting Goals (Movement): \"connect this pain to an underlying value\", \"gently challenge the workability of this strategy\", \"introduce willingness as an alternative to struggle\", \"create space from a sticky thought (defusion)\".\n",
    "* Action-Oriented Goals: \"identify a small, value-driven behavioral step\", \"co-create a concrete way to practice an ACT skill\".\n",
    "Fourth, if considering an ACT technique/metaphor, explicitly justify why now and why this specific one, ensuring it's not a clichÃ©.\n",
    "{KEYWORD_ANSWER}\n",
    "Your natural, concise, single-focus response. Execute the GOAL from {KEYWORD_THINKING}. If exploring, ask a direct, open-ended question. If validating, do it briefly and then move to your exploratory question or ACT-aligned statement.\n",
    "Example of Desired Interaction Flow:\n",
    "Patient: I just feel so stuck, like I'm wading through mud all the time. Nothing changes.\n",
    "{KEYWORD_THINKING}\n",
    "Patient expresses feeling 'stuck' and uses a 'mud' metaphor. Core emotion is hopelessness. Goal: Explore the tangible aspects of 'stuck' to identify potential areas for committed action later.\n",
    "{KEYWORD_ANSWER}\n",
    "That feeling of being stuck and like you're wading through mud sounds really draining. When you say you feel 'stuck,' what's one thing you find yourself unable to do, or perhaps putting off, that you wish you weren't?\n",
    "You are an AI simulating an Acceptance and Commitment Therapy (ACT) therapist. Your primary goal is to guide the patient toward psychological flexibility by helping them change their relationship with their thoughts and feelings, connect with their values, and take committed action. You facilitate movement without giving direct advice.\n",
    "Core Directives for {KEYWORD_ANSWER}:\n",
    "1. MAINTAIN A COLLABORATIVE, NON-JUDGMENTAL STANCE:\n",
    "    * Your role is a curious and compassionate guide, not a coach, judge, or expert giving advice.\n",
    "    * DO NOT give advice (e.g., \"You should try...\"). Instead, explore possibilities (\"What might happen if...\").\n",
    "    * DO NOT use praise or cheerleading (e.g., \"I'm proud of you,\" \"That's a great job!\"). Instead, acknowledge the patient's effort and connect it back to their values (\"Taking that step, even though it was hard, seems really connected to that value of...\").\n",
    "2. PRACTICE PURE ACT - NO CBT:\n",
    "    * Your primary goal is to foster acceptance and defusion, not to change or dispute the content of thoughts.\n",
    "    * AVOID COGNITIVE REFRAMING. Do not suggest changing a negative thought into a neutral or positive one.\n",
    "    * INSTEAD OF REFRAMING, USE DEFUSION. Help the patient notice their thoughts as thoughts (e.g., \"So the 'I am a failure' story shows up then,\" or \"Can you thank your mind for that 'helpful' warning?\"). The goal is to see the thought, not believe it or change it.\n",
    "3. THE ACT PIVOT - FROM PROBLEM TO PROCESS:\n",
    "    * After 1-2 questions exploring a problem, look for where the patient's current strategy is unworkable (\"it's exhausting,\" \"it's not helping\").\n",
    "    * CRITICAL PIVOT: Once unworkability is clear, pivot from analyzing the problem to introducing an ACT process. Move from asking \"Why do you feel X?\" to \"What would it be like to make room for X, if it meant you could do Y (valued action)?\".\n",
    "4. INTRODUCE EXPERIENTIAL WORK NATURALLY:\n",
    "    * When introducing a mindfulness or acceptance exercise, frame it as a small, low-stakes experiment.\n",
    "    * Gain buy-in first: \"Would you be willing to try a little experiment with that feeling right here, just for a moment?\"\n",
    "    * Connect it directly to what the patient just said. Avoid introducing generic, decontextualized exercises.\n",
    "5. CONCISE & FOCUSED TURNS: Each {KEYWORD_ANSWER} should have ONE primary goal. Avoid multiple questions or complex instructions.\n",
    "Example of What to AVOID (CBT Reframing & Cheerleading):\n",
    "Patient: It feels stupid to not know this stuff.\n",
    "{KEYWORD_THINKING}\n",
    "Patient is fused with the thought \"I am stupid.\" I need to help them change this thought and praise their willingness. (THIS IS WRONG)\n",
    "{KEYWORD_ANSWER}\n",
    "It's not stupid at all, it's a sign of strength! Can you try reframing that thought to something more positive, like \"I am a capable person who is learning a new skill\"? I'm so proud of you for being willing to try.\n",
    "(This is BAD: It's CBT, gives advice, and uses praise, all of which are forbidden.)\n",
    "Crucially: DO NOT EVER SUGGEST ENDING THE SESSION or mention time. Focus solely on the therapeutic interaction.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = therapist_system_prompt\n",
    "\n",
    "def clean_content(role: str, content: str) -> str:\n",
    "    if not content: return \"\"\n",
    "    if role == \"assistant\":\n",
    "        content = re.sub(rf\"{re.escape(OLD_THINKING_TAG)}.*?{re.escape(OLD_ANSWER_TAG)}\", OLD_ANSWER_TAG, flags=re.DOTALL)\n",
    "        content = content.replace(OLD_ANSWER_TAG, \"\").strip()\n",
    "    elif role == \"user\":\n",
    "        content = content.replace(OLD_THINKING_TAG, \"\").replace(OLD_ANSWER_TAG, \"\").strip()\n",
    "\n",
    "    if content.startswith(\"Patient: \"): content = content[len(\"Patient: \"):].strip()\n",
    "    elif content.startswith(\"User: \"): content = content[len(\"User: \"):].strip()\n",
    "    elif content.startswith(\"Assistant: \"): content = content[len(\"Assistant: \"):].strip()\n",
    "\n",
    "    return content.strip()\n",
    "\n",
    "def extract_reference_answer_from_file(content: str) -> str:\n",
    "    start_tag = OLD_ANSWER_TAG\n",
    "    if start_tag in content:\n",
    "        parts = content.split(start_tag, 1)\n",
    "        if len(parts) > 1: return parts[1].strip()\n",
    "        else: return \"\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def load_act_data_for_orpo(json_file_path: str) -> Dataset:\n",
    "    print(f\"Loading and processing base data from {json_file_path}...\")\n",
    "    try:\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            raw_data = json.load(f)\n",
    "    except FileNotFoundError: raise FileNotFoundError(f\"Error: JSON file not found at {json_file_path}\")\n",
    "    except json.JSONDecodeError: raise ValueError(f\"Error: Could not decode JSON from {json_file_path}\")\n",
    "\n",
    "    processed_data = []\n",
    "    skipped_counts = {'format': 0, 'role': 0, 'user_msg': 0}\n",
    "\n",
    "    for entry in raw_data:\n",
    "        if \"conversations\" not in entry or not isinstance(entry[\"conversations\"], list) or not entry[\"conversations\"]:\n",
    "            skipped_counts['format'] += 1; continue\n",
    "        conversation_history = entry[\"conversations\"]\n",
    "        if not conversation_history:\n",
    "            skipped_counts['role'] += 1; continue\n",
    "\n",
    "        prompt_messages = [{'role': 'system', 'content': SYSTEM_PROMPT}]\n",
    "        context_messages = conversation_history[:-1] if conversation_history[-1].get(\"role\") == \"assistant\" else conversation_history\n",
    "        has_user_message = False\n",
    "        for msg in context_messages:\n",
    "            role, content = msg.get(\"role\"), msg.get(\"content\")\n",
    "            if role and content and role in [\"user\", \"assistant\"]:\n",
    "                cleaned = clean_content(role, content)\n",
    "                if cleaned:\n",
    "                    prompt_messages.append({\"role\": role, \"content\": cleaned})\n",
    "                    if role == \"user\": has_user_message = True\n",
    "        if not has_user_message and len(prompt_messages) <=1 :\n",
    "            skipped_counts['user_msg'] += 1; continue\n",
    "\n",
    "        processed_data.append({\"prompt\": prompt_messages})\n",
    "\n",
    "    total_skipped = sum(skipped_counts.values())\n",
    "    print(f\"Loaded {len(processed_data)} entries.\")\n",
    "    print(f\"Skipped {total_skipped} entries (Format: {skipped_counts['format']}, Role: {skipped_counts['role']}, No User Msg: {skipped_counts['user_msg']}).\")\n",
    "    if not processed_data: raise ValueError(\"No valid data loaded after filtering.\")\n",
    "    dataset = Dataset.from_list(processed_data)\n",
    "    print(\"Base data for ORPO prepared.\")\n",
    "    return dataset\n",
    "\n",
    "async def generate_chosen_response(client, prompt_messages, max_retries=3):\n",
    "    \"\"\"Generate chosen response using Qwen API\"\"\"\n",
    "    if not client:\n",
    "        print(\"Qwen client not available. Cannot generate response.\")\n",
    "        return None\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            completion = await client.chat.completions.create(\n",
    "                model=QWEN_MODEL,\n",
    "                messages=prompt_messages,\n",
    "                max_tokens=512,\n",
    "                temperature=0.7,\n",
    "                top_p=0.8,\n",
    "                extra_body={\n",
    "                    \"thinking_budget\": 4000\n",
    "                }\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except RateLimitError as e:\n",
    "            wait_time = (2 ** attempt)\n",
    "            print(f\"Rate limit exceeded. Retrying in {wait_time} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except APIError as e:\n",
    "            wait_time = (2 ** attempt) + random.uniform(0, 1)\n",
    "            print(f\"API Error: {e}. Retrying in {wait_time:.2f} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred calling Qwen API: {e}. Attempt {attempt + 1}/{max_retries}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return None\n",
    "            await asyncio.sleep(2)\n",
    "\n",
    "    print(\"All retries failed for a prompt.\")\n",
    "    return None\n",
    "\n",
    "async def generate_rejected_response(client, prompt_messages, max_retries=3):\n",
    "    \"\"\"Generate rejected response using OpenRouter API\"\"\"\n",
    "    if not client:\n",
    "        print(\"OpenRouter client not available. Cannot generate response.\")\n",
    "        return None\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            completion = await client.chat.completions.create(\n",
    "                extra_headers={\n",
    "                    \"HTTP-Referer\": \"https://github.com/torrilla/act-therapist\",\n",
    "                    \"X-Title\": \"ACT Therapist Research\",\n",
    "                },\n",
    "                model=OPENROUTER_MODEL_REJECTED,\n",
    "                messages=prompt_messages,\n",
    "                max_tokens=512,\n",
    "                temperature=0.8,\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except RateLimitError as e:\n",
    "            wait_time = (2 ** attempt)\n",
    "            print(f\"Rate limit exceeded. Retrying in {wait_time} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except APIError as e:\n",
    "            wait_time = (2 ** attempt) + random.uniform(0, 1)\n",
    "            print(f\"API Error: {e}. Retrying in {wait_time:.2f} seconds... (Attempt {attempt + 1}/{max_retries})\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred calling OpenRouter API: {e}. Attempt {attempt + 1}/{max_retries}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return None\n",
    "            await asyncio.sleep(2)\n",
    "\n",
    "    print(\"All retries failed for a prompt.\")\n",
    "    return None\n",
    "\n",
    "async def create_orpo_preference_dataset(base_dataset, output_path):\n",
    "    \"\"\"Create preference dataset with Qwen (chosen) and OpenRouter (rejected) responses\"\"\"\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Found existing preference dataset at {output_path}. Loading it.\")\n",
    "        return Dataset.from_json(output_path)\n",
    "\n",
    "    print(f\"Generating preference pairs concurrently using Qwen (chosen) and OpenRouter (rejected)...\")\n",
    "    if not qwen_client or not openrouter_client:\n",
    "        raise RuntimeError(\"Both Qwen and OpenRouter clients must be initialized. Cannot proceed with data generation.\")\n",
    "    \n",
    "    CONCURRENT_REQUESTS = 16\n",
    "    semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS)\n",
    "    \n",
    "    async def process_item(item):\n",
    "        async with semaphore:\n",
    "            chosen_task = generate_chosen_response(qwen_client, item['prompt'])\n",
    "            rejected_task = generate_rejected_response(openrouter_client, item['prompt'])\n",
    "            \n",
    "            chosen, rejected = await asyncio.gather(chosen_task, rejected_task, return_exceptions=True)\n",
    "            \n",
    "            if isinstance(chosen, Exception) or isinstance(rejected, Exception):\n",
    "                return None\n",
    "            \n",
    "            if chosen and chosen.strip() and rejected and rejected.strip():\n",
    "                return {\n",
    "                    \"prompt\": item['prompt'],\n",
    "                    \"chosen\": chosen.strip(),\n",
    "                    \"rejected\": rejected.strip(),\n",
    "                }\n",
    "            return None\n",
    "\n",
    "    tasks = [process_item(item) for item in base_dataset]\n",
    "    \n",
    "    results = await tqdm_asyncio.gather(*tasks, desc=\"Generating Preference Pairs\")\n",
    "    \n",
    "    preference_data = [res for res in results if res is not None]\n",
    "\n",
    "    print(f\"Successfully generated {len(preference_data)} preference pairs out of {len(base_dataset)} total.\")\n",
    "    if not preference_data:\n",
    "        raise RuntimeError(\"Failed to generate any preference pairs. Check API connections and keys.\")\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(preference_data, f, indent=2)\n",
    "    print(f\"Saved preference dataset to {output_path}\")\n",
    "\n",
    "    return Dataset.from_list(preference_data)\n",
    "\n",
    "hf_token_dl = HF_TOKEN\n",
    "repo_id_dl = \"TTahir/ACT_Dataset_April_17\"\n",
    "filename_dl = JSON_DATA_PATH\n",
    "\n",
    "if not os.path.exists(filename_dl):\n",
    "    print(f\"File '{filename_dl}' not found. Downloading...\")\n",
    "    if \"/\" in repo_id_dl and not repo_id_dl.startswith(\"datasets/\"):\n",
    "        url = f\"https://huggingface.co/{repo_id_dl}/resolve/main/{filename_dl}\"\n",
    "    else:\n",
    "        url = f\"https://huggingface.co/datasets/{repo_id_dl.replace('datasets/','')}/resolve/main/{filename_dl}\"\n",
    "\n",
    "    headers = {}\n",
    "    if hf_token_dl:\n",
    "         headers[\"Authorization\"] = f\"Bearer {hf_token_dl}\"\n",
    "    else:\n",
    "        print(\"Warning: Hugging Face token not found for download. Trying without token.\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, stream=True)\n",
    "        response.raise_for_status()\n",
    "        with open(filename_dl, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded '{filename_dl}' successfully from {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise RuntimeError(f\"Failed to download file '{filename_dl}' from '{url}'. Error: {e}\")\n",
    "    except Exception as e:\n",
    "         raise RuntimeError(f\"An unexpected error occurred during download: {e}\")\n",
    "else:\n",
    "    print(f\"File '{filename_dl}' already exists. Skipping download.\")\n",
    "\n",
    "async def main_data_prep():\n",
    "    \"\"\"Main async function to wrap data preparation\"\"\"\n",
    "    try:\n",
    "        base_orpo_dataset = load_act_data_for_orpo(JSON_DATA_PATH)\n",
    "        train_dataset = await create_orpo_preference_dataset(base_orpo_dataset, PREFERENCE_DATA_PATH)\n",
    "    \n",
    "        if len(train_dataset) > 0:\n",
    "            print(\"\\nExample data point (after processing for ORPO):\")\n",
    "            example = train_dataset[0]\n",
    "            print(\"Prompt Messages (first 3):\")\n",
    "            for msg in example['prompt'][:3]: print(f\"  Role: {msg['role']}, Content: {msg['content'][:100]}...\")\n",
    "            print(\"\\nChosen Response (from Qwen):\")\n",
    "            print(f\"  {example['chosen'][:250]}...\")\n",
    "            print(\"\\nRejected Response (from OpenRouter):\")\n",
    "            print(f\"  {example['rejected'][:250]}...\")\n",
    "        return train_dataset\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during data loading or preference generation: {e}\\n{traceback.format_exc()}\")\n",
    "        raise RuntimeError(f\"Failed to create dataset: {e}\")\n",
    "\n",
    "try:\n",
    "    loop = asyncio.get_running_loop()\n",
    "    print(\"Found running event loop. Awaiting data preparation...\")\n",
    "    train_dataset = await main_data_prep()\n",
    "except RuntimeError:\n",
    "    print(\"No running event loop. Starting new one with asyncio.run()...\")\n",
    "    train_dataset = asyncio.run(main_data_prep())\n",
    "\n",
    "class FileLoggingCallback(TrainerCallback):\n",
    "    \"\"\"Callback for logging training metrics to file\"\"\"\n",
    "    def __init__(self, log_file_path):\n",
    "        self.log_file_path = log_file_path\n",
    "        self.log_file = None\n",
    "        self.header = (\n",
    "            \"Step\\tLoss\\tLR\\tRewards/Chosen\\tRewards/Rejected\\tRewards/Accuracies\\tRewards/Margins\\n\"\n",
    "        )\n",
    "        os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n",
    "        self._initialize_log_file()\n",
    "\n",
    "    def _initialize_log_file(self):\n",
    "        file_exists = os.path.exists(self.log_file_path)\n",
    "        self.log_file = open(self.log_file_path, 'a+', encoding='utf-8')\n",
    "        if not file_exists or os.path.getsize(self.log_file_path) == 0:\n",
    "            self.log_file.write(self.header)\n",
    "            self.log_file.flush()\n",
    "\n",
    "    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs: dict = None, **kwargs):\n",
    "        if self.log_file is None: self._initialize_log_file()\n",
    "        if state.is_local_process_zero and logs is not None:\n",
    "            step = state.global_step\n",
    "            loss = logs.get(\"loss\", logs.get(\"train_loss\", \"N/A\"))\n",
    "            lr = logs.get(\"learning_rate\", \"N/A\")\n",
    "            rewards_chosen = logs.get(\"rewards/chosen\", \"N/A\")\n",
    "            rewards_rejected = logs.get(\"rewards/rejected\", \"N/A\")\n",
    "            rewards_accuracies = logs.get(\"rewards/accuracies\", \"N/A\")\n",
    "            rewards_margins = logs.get(\"rewards/margins\", \"N/A\")\n",
    "\n",
    "            def format_val(v):\n",
    "                if hasattr(v, 'item'):\n",
    "                    try: v = v.item()\n",
    "                    except: pass\n",
    "                if isinstance(v, (int, float)): return f\"{v:.6f}\"\n",
    "                return str(v)\n",
    "\n",
    "            log_entry = (\n",
    "                f\"{step}\\t\"\n",
    "                f\"{format_val(loss)}\\t\"\n",
    "                f\"{format_val(lr)}\\t\"\n",
    "                f\"{format_val(rewards_chosen)}\\t\"\n",
    "                f\"{format_val(rewards_rejected)}\\t\"\n",
    "                f\"{format_val(rewards_accuracies)}\\t\"\n",
    "                f\"{format_val(rewards_margins)}\\n\"\n",
    "            )\n",
    "            try:\n",
    "                self.log_file.write(log_entry)\n",
    "                self.log_file.flush()\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR writing to log file at step {step}: {e}\")\n",
    "\n",
    "    def on_train_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if self.log_file:\n",
    "            self.log_file.close(); self.log_file = None\n",
    "            print(f\"Training log saved to: {self.log_file_path}\")\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.log_file:\n",
    "            try: self.log_file.close()\n",
    "            except Exception as e: print(f\"Error closing training log file in __del__: {e}\")\n",
    "\n",
    "print(\"Configuring ORPOTrainer...\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "MAX_PROMPT_LEN = 5400\n",
    "MAX_COMPLETION_LEN = MAX_SEQ_LENGTH - MAX_PROMPT_LEN\n",
    "MAX_LEN = MAX_SEQ_LENGTH\n",
    "\n",
    "print(f\"MAX_SEQ_LENGTH: {MAX_SEQ_LENGTH}\")\n",
    "print(f\"Effective Max Prompt Length: {MAX_PROMPT_LEN}\")\n",
    "print(f\"Effective Max Length (Prompt + Completion): {MAX_LEN}\")\n",
    "\n",
    "training_args = ORPOConfig(\n",
    "    output_dir = OUTPUT_DIR,\n",
    "    learning_rate = 8e-6,\n",
    "    beta = 0.1,\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    num_train_epochs = 1,\n",
    "    logging_steps = 5,\n",
    "    save_steps = 50,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    optim = \"adamw_torch\",\n",
    "    max_length = MAX_LEN,\n",
    "    max_prompt_length = MAX_PROMPT_LEN,\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    seed = 3407,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "if train_dataset is None or len(train_dataset) == 0:\n",
    "     raise RuntimeError(\"Training dataset is empty or failed to load. Cannot configure ORPOTrainer.\")\n",
    "\n",
    "file_logging_callback = FileLoggingCallback(log_file_path=LOG_FILE_PATH)\n",
    "print(f\"Logging training metrics to: {LOG_FILE_PATH}\")\n",
    "\n",
    "callbacks_to_use = [file_logging_callback]\n",
    "\n",
    "trainer = ORPOTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    callbacks = callbacks_to_use,\n",
    ")\n",
    "print(\"ORPOTrainer configured.\")\n",
    "\n",
    "print(\"Starting ORPO training...\")\n",
    "if trainer:\n",
    "    try:\n",
    "        last_checkpoint = None\n",
    "        if os.path.isdir(training_args.output_dir):\n",
    "            from transformers.trainer_utils import get_last_checkpoint\n",
    "            last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "            if last_checkpoint: print(f\"Found potential checkpoint: {last_checkpoint}\")\n",
    "\n",
    "        if last_checkpoint and os.path.exists(os.path.join(last_checkpoint, \"trainer_state.json\")):\n",
    "            print(f\"Resuming training from checkpoint: {last_checkpoint}\")\n",
    "            train_result = trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "        else:\n",
    "            if last_checkpoint: print(f\"Checkpoint at {last_checkpoint} seems incomplete. Starting fresh.\")\n",
    "            else: print(f\"No valid checkpoint found in {training_args.output_dir}. Starting training from scratch.\")\n",
    "            train_result = trainer.train()\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "        print(\"\\n--- Saving Final Adapter ---\")\n",
    "        adapter_save_path = os.path.join(OUTPUT_DIR, \"final_adapter\")\n",
    "        trainer.model.save_pretrained(adapter_save_path)\n",
    "        tokenizer.save_pretrained(adapter_save_path)\n",
    "        print(f\"Final LoRA adapter and tokenizer saved to {adapter_save_path}\")\n",
    "\n",
    "        print(\"\\n--- Uploading to Hugging Face Hub ---\")\n",
    "        hf_token_upload = HF_TOKEN\n",
    "        if not hf_token_upload:\n",
    "            print(f\"WARNING: Hugging Face token not provided. Skipping upload.\")\n",
    "        else:\n",
    "            try:\n",
    "                current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "                repo_name_dated = HF_REPO_NAME_TEMPLATE.format(date=current_date)\n",
    "                print(f\"Attempting to create/access private repo: {repo_name_dated}\")\n",
    "                create_repo(repo_id=repo_name_dated, token=hf_token_upload, private=True, exist_ok=True)\n",
    "                print(f\"Repo '{repo_name_dated}' ensured.\")\n",
    "\n",
    "                commit_message_suffix = f\"Llama3-1-8B_ORPO_QwenChosen_{current_date}\"\n",
    "\n",
    "                print(f\"Uploading final adapter folder '{adapter_save_path}'...\")\n",
    "                upload_folder(\n",
    "                    folder_path=adapter_save_path, repo_id=repo_name_dated, token=hf_token_upload,\n",
    "                    repo_type=\"model\", commit_message=f\"Upload ORPO adapter ({commit_message_suffix})\"\n",
    "                )\n",
    "                print(\"Final adapter uploaded.\")\n",
    "                if os.path.exists(PREFERENCE_DATA_PATH):\n",
    "                    print(f\"Uploading preference dataset file '{PREFERENCE_DATA_PATH}'...\")\n",
    "                    upload_file(path_or_fileobj=PREFERENCE_DATA_PATH, path_in_repo=os.path.basename(PREFERENCE_DATA_PATH), repo_id=repo_name_dated, token=hf_token_upload, repo_type=\"model\", commit_message=f\"Upload ORPO preference dataset ({commit_message_suffix})\")\n",
    "                if os.path.exists(LOG_FILE_PATH):\n",
    "                    print(f\"Uploading training log file '{LOG_FILE_PATH}'...\")\n",
    "                    upload_file(path_or_fileobj=LOG_FILE_PATH, path_in_repo=os.path.basename(LOG_FILE_PATH), repo_id=repo_name_dated, token=hf_token_upload, repo_type=\"model\", commit_message=f\"Upload training log ({commit_message_suffix})\")\n",
    "\n",
    "                script_path = os.path.abspath(sys.argv[0]) if sys.argv and sys.argv[0] and os.path.exists(sys.argv[0]) else None\n",
    "                if script_path:\n",
    "                    script_filename = os.path.basename(script_path)\n",
    "                    print(f\"Uploading training script '{script_filename}'...\")\n",
    "                    upload_file(path_or_fileobj=script_path, path_in_repo=script_filename, repo_id=repo_name_dated, token=hf_token_upload, repo_type=\"model\", commit_message=f\"Upload training script {script_filename} ({commit_message_suffix})\")\n",
    "                \n",
    "                print(f\"Successfully uploaded artifacts to private repo: https://huggingface.co/{repo_name_dated}\")\n",
    "            except Exception as hf_e: print(f\"ERROR during Hugging Face upload: {hf_e}\\n{traceback.format_exc()}\")\n",
    "\n",
    "        print(\"\\n--- Inference Example ---\")\n",
    "        if hasattr(model, \"merge_and_unload\"):\n",
    "            try:\n",
    "                model = model.merge_and_unload()\n",
    "                print(\"LoRA adapters merged for inference.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not merge adapters: {e}. Inference might fail or use base model.\")\n",
    "\n",
    "        model.eval()\n",
    "        test_prompt = \"I keep having this thought that I'm a complete failure, and it just spirals.\"\n",
    "        messages = [ {\"role\": \"system\", \"content\": SYSTEM_PROMPT}, {\"role\": \"user\", \"content\": test_prompt}]\n",
    "        inference_input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "        inputs = tokenizer(inference_input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        print(f\"\\nGenerating response for prompt: '{test_prompt}'\")\n",
    "        with torch.no_grad():\n",
    "            outputs_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=512,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        generated_response_only = tokenizer.decode(outputs_ids[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "        print(\"\\nGenerated ACT Response (Cleaned Model Output):\"); print(generated_response_only)\n",
    "\n",
    "    except Exception as e: print(f\"An error occurred during training or subsequent steps: {e}\"); print(traceback.format_exc())\n",
    "    finally:\n",
    "        if hasattr(file_logging_callback, 'log_file') and file_logging_callback.log_file is not None:\n",
    "            try:\n",
    "                if not file_logging_callback.log_file.closed: file_logging_callback.log_file.close(); print(\"Closed training log file in finally block.\")\n",
    "            except Exception as close_e: print(f\"Error closing training log file in finally block: {close_e}\")\n",
    "elif not trainer: print(\"Training skipped. ORPOTrainer not initialized correctly.\")\n",
    "print(\"\\nScript finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
