{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4933cad-997c-4959-acbe-81dc8e419aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all folders in working directory, leave files alone\n",
    "!find . -mindepth 1 -maxdepth 1 -type d -exec rm -r {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a5703-88a2-40b1-bbdc-114c86134a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unsloth\n",
    "!pip install instructor\n",
    "!pip install openai \n",
    "!pip install pydantic\n",
    "!pip install dotenv\n",
    "!pip install huggingface_hub\n",
    "!python -m pip install --upgrade typing_extensions\n",
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f369a33-b162-44ab-b298-e4fddf3ed7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 08-26 00:12:43 [__init__.py:241] Automatically detected platform cuda.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Logging initialized for model: ORPO. All logs will be saved to simulation_outputs_orpo/simulation_run.log\n",
      "DEBUG:__main__:API keys seem to be set (not placeholders).\n",
      "INFO:__main__:--- ACT Therapy Chatbot Multi-Simulation Script (ORPO Model) ---\n",
      "INFO:__main__:Patient Response Supervisor Enabled: False\n",
      "INFO:__main__:Attempting to run 150 simulations.\n",
      "INFO:__main__:--- Initializing Models (once for all simulations) ---\n",
      "INFO:__main__:Adapter not found or incomplete locally. Downloading from TTahir/act-therapist-orpo-llama31-3b-2025-08-25 to downloaded_orpo_adapters/act-therapist-orpo-llama31-3b-2025-08-25...\n",
      "INFO:__main__:Successfully accessed repo info for TTahir/act-therapist-orpo-llama31-3b-2025-08-25 using provided token.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcac79a5ee4b4760b8dbb44c254198ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8441d180041e4b339aa6a46e53c1d9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d64ddf1f12b4c548467ef9d2c0f8da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/940 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7bc461d731453f93134f0882d5f71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/389M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33aec4aef6f74bd7913357b0914e84b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/3.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da645810aef4c19a87525bf31469e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ipykernel_launcher.py:   0%|          | 0.00/512 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4176b09a82488094dbbc916756d0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "orpo_preference_dataset.json:   0%|          | 0.00/15.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2217880dd28469886d65774c4ae5f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645fdd8af4924e0799b23c68d47104e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14b99d4fc5247d18473c176e35a517f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f29c8ee3e64915b24d9de47f6d3d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_log.tsv:   0%|          | 0.00/1.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Adapter downloaded successfully to /workspace/Sims_ORPO_no_COT_Aug_25/downloaded_orpo_adapters/act-therapist-orpo-llama31-3b-2025-08-25. Content: ['training_log.tsv', 'tokenizer_config.json', 'tokenizer.json', 'special_tokens_map.json', 'orpo_preference_dataset.json', 'ipykernel_launcher.py', 'chat_template.jinja', 'adapter_model.safetensors', 'adapter_config.json', 'README.md', '.gitattributes', '.cache']\n",
      "INFO:__main__:Loading ORPO therapist model from adapter: /workspace/Sims_ORPO_no_COT_Aug_25/downloaded_orpo_adapters/act-therapist-orpo-llama31-3b-2025-08-25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.9: Fast Llama patching. Transformers: 4.55.4. vLLM: 0.10.1.1.\n",
      "   \\\\   /|    NVIDIA RTX A5000. Num GPUs = 1. Max memory: 23.547 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f56b3e6622e48099f81190c6593c457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.9 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n",
      "INFO:__main__:ORPO therapist model and tokenizer loaded successfully.\n",
      "INFO:__main__:Initializing OpenAI client...\n",
      "INFO:__main__:OpenAI client initialized successfully.\n",
      "INFO:__main__:--- All models initialized successfully. ---\n",
      "INFO:__main__:Found existing patient profile file: 'standardized_patient_profiles.json'.\n",
      "INFO:__main__:Loaded 150 profiles. Using the first 150 for this run.\n",
      "INFO:__main__:--- Preparing for Simulation 1/150 ---\n",
      "INFO:__main__:Using standardized profile 1 (Hash: 0276eb8e8fdb0e6b00dec0798b169f3a).\n",
      "INFO:__main__:--- Starting Simulation 1 (Archetype: The Anxious Fortune-Teller) ---\n",
      "DEBUG:__main__:Simulation 1 - Patient Profile: {\n",
      "  \"full_scenario_text\": \"Patient is an elderly individual (80-99), identifies as non-binary, works as a manager, and is currently widowed. ARCHETYPE: The Anxious Fortune-Teller. Primary concern involves PTSD (flashbacks, nightmares, hypervigilance related to past trauma), particularly manifesting as: Feeling overwhelmed by sadness and lack of motivation since significant family conflict, impacting their relationship.. This seems exacerbated by significant family conflict. Had a somewhat chaotic childhood with inconsistent parenting. Their typical coping mechanism is using humor/sarcasm. Personality traits include being gregarious, optimistic, and easily distracted. They have limited social support currently. Interaction Style: Catastrophizing/Future-Focused (Immediately jumps to the worst-case scenario in any situation. Speaks about future disasters as if they are certain facts. Often uses absolute language like 'always,' 'never,' or 'guaranteed.'). Psychological Mindedness: Moderate.\",\n",
      "  \"archetype_name\": \"The Anxious Fortune-Teller\",\n",
      "  \"presenting_problem_detail\": \"Feeling overwhelmed by sadness and lack of motivation since significant family conflict, impacting their relationship.\",\n",
      "  \"interaction_style_name\": \"Catastrophizing/Future-Focused\",\n",
      "  \"interaction_style_description\": \"Immediately jumps to the worst-case scenario in any situation. Speaks about future disasters as if they are certain facts. Often uses absolute language like 'always,' 'never,' or 'guaranteed.'\",\n",
      "  \"psych_mindedness_level\": \"Moderate\",\n",
      "  \"profile_summary_for_prompt\": \"You are an elderly individual, working as a manager. You've been dealing with PTSD which has been particularly challenging due to significant family conflict. Your main struggle right now is: Feeling overwhelmed by sadness and lack of motivation since significant family conflict, impacting their relationship.. You tend to be gregarious, optimistic, and easily distracted. Crucially, for this session, you must adopt the following persona: Your mind is a 'fortune-telling' machine that only predicts disaster. When you talk about a problem, you immediately describe the worst possible chain of events that will 'definitely' happen. You are completely hooked by these stories. If the therapist asks you to consider other outcomes, you dismiss them as unrealistic. Your anxiety is tied to these future predictions, not the present moment.\",\n",
      "  \"profile_hash\": \"0276eb8e8fdb0e6b00dec0798b169f3a\"\n",
      "}\n",
      "INFO:__main__:Simulation 1 - Patient profile saved to simulation_outputs_orpo/simulation_1_patient_profile.txt\n",
      "DEBUG:__main__:Sending to OpenAI (gpt-5-mini) patient model. Last message content: Here is your persona for this therapy session:\n",
      "You are an elderly individual, working as a manager. ...\n",
      "DEBUG:__main__:OpenAI patient response: I'm an older manager and lately I've been overwhelmed by sadness and can't get motivated since that huge family fight. My head's like a fortune-tellin...\n",
      "INFO:__main__:Simulation 1 - Turn 0 (Patient Initiation): I'm an older manager and lately I've been overwhelmed by sadness and can't get motivated since that huge family fight. My head's like a fortune-tellin...\n",
      "INFO:__main__:Simulation 1 - Starting Turn 1\n",
      "DEBUG:__main__:Simulation 1 - Turn 1 - Therapist (ORPO) generating response...\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "INFO:__main__:Simulation 1 - Turn 1 - Therapist (Answer): Those stories feel like they're pulling you in, making it hard to see anything else. When that \"fortune-telling machine\" shows up, what happens if you...\n",
      "DEBUG:__main__:Simulation 1 - Turn 1 - Patient (OpenAI) generating response...\n",
      "DEBUG:__main__:Simulation 1 - Turn 1 - Patient response supervisor is DISABLED.\n",
      "DEBUG:__main__:Sending to OpenAI (gpt-5-mini) patient model. Last message content: Those stories feel like they're pulling you in, making it hard to see anything else. When that \"fort...\n",
      "DEBUG:__main__:OpenAI patient response: I want that to help, but when I try to just notice it, the doom-visions get louder and I can't seem to turn them off. It feels like stepping back woul...\n",
      "INFO:__main__:Simulation 1 - Turn 1 - Patient: I want that to help, but when I try to just notice it, the doom-visions get louder and I can't seem to turn them off. It feels like stepping back woul...\n",
      "INFO:__main__:Simulation 1 - Starting Turn 2\n",
      "DEBUG:__main__:Simulation 1 - Turn 2 - Therapist (ORPO) generating response...\n",
      "INFO:__main__:Simulation 1 - Turn 2 - Therapist (Answer): Those outcomes feel like they're already happening, even if they're just thoughts. What matters isn't that you can \"just notice\" them; it's that you'r...\n",
      "DEBUG:__main__:Simulation 1 - Turn 2 - Patient (OpenAI) generating response...\n",
      "DEBUG:__main__:Simulation 1 - Turn 2 - Patient response supervisor is DISABLED.\n",
      "DEBUG:__main__:Sending to OpenAI (gpt-5-mini) patient model. Last message content: Those outcomes feel like they're already happening, even if they're just thoughts. What matters isn'...\n",
      "DEBUG:__main__:OpenAI patient response: I want to try, I really do, but when I try to act the fortune-telling kicks in â€” I picture them cutting me off, losing the house, then getting fired, ...\n",
      "INFO:__main__:Simulation 1 - Turn 2 - Patient: I want to try, I really do, but when I try to act the fortune-telling kicks in â€” I picture them cutting me off, losing the house, then getting fired, ...\n",
      "INFO:__main__:Simulation 1 - Starting Turn 3\n",
      "DEBUG:__main__:Simulation 1 - Turn 3 - Therapist (ORPO) generating response...\n",
      "INFO:__main__:Simulation 1 - Turn 3 - Therapist (Answer): It sounds like the thought of \"acting\" feels like it would mean stepping into those worst-case scenarios anyway. When you're trying to make a step, li...\n",
      "DEBUG:__main__:Simulation 1 - Turn 3 - Patient (OpenAI) generating response...\n",
      "DEBUG:__main__:Simulation 1 - Turn 3 - Patient response supervisor is DISABLED.\n",
      "DEBUG:__main__:Sending to OpenAI (gpt-5-mini) patient model. Last message content: It sounds like the thought of \"acting\" feels like it would mean stepping into those worst-case scena...\n",
      "DEBUG:__main__:OpenAI patient response: I'm trying to imagine that, but it never sticks â€” the moment I try to make room for anything else the machine starts yelling the worst: if I go to wor...\n",
      "INFO:__main__:Simulation 1 - Turn 3 - Patient: I'm trying to imagine that, but it never sticks â€” the moment I try to make room for anything else the machine starts yelling the worst: if I go to wor...\n",
      "INFO:__main__:Simulation 1 - Starting Turn 4\n",
      "DEBUG:__main__:Simulation 1 - Turn 4 - Therapist (ORPO) generating response...\n",
      "INFO:__main__:Simulation 1 - Turn 4 - Therapist (Answer): The \"pointless\" feeling makes sense - it sounds like you're wondering why bother if those outcomes are already \"guaranteed\". When you notice that stor...\n",
      "DEBUG:__main__:Simulation 1 - Turn 4 - Patient (OpenAI) generating response...\n",
      "DEBUG:__main__:Simulation 1 - Turn 4 - Patient response supervisor is DISABLED.\n",
      "DEBUG:__main__:Sending to OpenAI (gpt-5-mini) patient model. Last message content: The \"pointless\" feeling makes sense - it sounds like you're wondering why bother if those outcomes a...\n",
      "DEBUG:__main__:OpenAI patient response: What matters most to me is not being abandoned â€” keeping my family, keeping the house, and not humiliating myself at work so I can still provide and b...\n",
      "INFO:__main__:Simulation 1 - Turn 4 - Patient: What matters most to me is not being abandoned â€” keeping my family, keeping the house, and not humiliating myself at work so I can still provide and b...\n",
      "INFO:__main__:Simulation 1 - Starting Turn 5\n",
      "DEBUG:__main__:Simulation 1 - Turn 5 - Therapist (ORPO) generating response...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from huggingface_hub import snapshot_download, HfApi\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "from functools import wraps\n",
    "import hashlib\n",
    "\n",
    "THERAPIST_CONFIG = {\n",
    "    \"model_name\": \"ORPO\",\n",
    "    \"hf_adapter_repo\": \"TTahir/act-therapist-orpo-llama31-3b-2025-08-25\",\n",
    "    \"local_adapter_dir_base\": \"downloaded_orpo_adapters\",\n",
    "    \"output_directory\": \"simulation_outputs_orpo\",\n",
    "    \"retry_max_attempts\": 10,\n",
    "}\n",
    "\n",
    "OPENAI_API_KEY = \"\"\n",
    "HF_AUTH_TOKEN = \"\"\n",
    "\n",
    "THERAPIST_MAX_SEQ_LENGTH = 9000\n",
    "THERAPIST_LOAD_IN_4BIT = False\n",
    "OPENAI_PATIENT_MODEL_NAME = \"gpt-5-mini\"\n",
    "NUM_TOTAL_SIMULATIONS = 150\n",
    "NUM_DIALOGUE_TURNS_PER_SIMULATION = 25\n",
    "RETRY_BASE_DELAY = 5\n",
    "KEYWORD_THINKING = \"Thinking:\"\n",
    "KEYWORD_ANSWER = \"Answer:\"\n",
    "PATIENT_PROFILES_FILENAME = \"standardized_patient_profiles.json\"\n",
    "\n",
    "USE_PATIENT_RESPONSE_SUPERVISOR = False\n",
    "\n",
    "os.makedirs(THERAPIST_CONFIG[\"output_directory\"], exist_ok=True)\n",
    "main_log_file_path = os.path.join(THERAPIST_CONFIG[\"output_directory\"], \"simulation_run.log\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "file_handler = logging.FileHandler(main_log_file_path, mode='w')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "logger.info(\"Logging initialized for model: %s. All logs will be saved to %s\", THERAPIST_CONFIG['model_name'], main_log_file_path)\n",
    "\n",
    "assert OPENAI_API_KEY and not OPENAI_API_KEY.startswith(\"sk-your_\") and OPENAI_API_KEY != \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\", \"OpenAI API Key is not set. Please replace placeholder.\"\n",
    "assert HF_AUTH_TOKEN != \"YOUR_HUGGINGFACE_TOKEN_HERE\", \"Hugging Face Token is not set. Please replace placeholder.\"\n",
    "logger.debug(\"API keys seem to be set (not placeholders).\")\n",
    "\n",
    "def retry_with_backoff(retries=THERAPIST_CONFIG[\"retry_max_attempts\"], base_delay=RETRY_BASE_DELAY, allowed_exceptions=(Exception,)):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            attempts = 0\n",
    "            while attempts < retries:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except allowed_exceptions as e:\n",
    "                    attempts += 1\n",
    "                    if attempts >= retries:\n",
    "                        logger.error(f\"Function {func.__name__} failed after {retries} attempts: {e}\", exc_info=True)\n",
    "                        raise\n",
    "                    wait_time = base_delay * (2 ** (attempts - 1)) + random.uniform(0, 1)\n",
    "                    logger.warning(f\"Attempt {attempts}/{retries} for {func.__name__} failed with {type(e).__name__}: {e}. Retrying in {wait_time:.2f}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "            return None\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def download_adapter_if_not_exists(repo_id: str, local_dir_base: str, hf_token: str):\n",
    "    repo_name_for_dir = repo_id.split('/')[-1]\n",
    "    local_dir = os.path.join(local_dir_base, repo_name_for_dir)\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(os.path.join(local_dir, \"adapter_config.json\")) and \\\n",
    "       os.path.exists(os.path.join(local_dir, \"adapter_model.safetensors\")):\n",
    "        logger.info(f\"Adapter appears to be cached locally at {local_dir}. Skipping download.\")\n",
    "        return local_dir\n",
    "\n",
    "    logger.info(f\"Adapter not found or incomplete locally. Downloading from {repo_id} to {local_dir}...\")\n",
    "    assert hf_token, \"Hugging Face token is required for downloading, especially private repos.\"\n",
    "    try:\n",
    "        api = HfApi()\n",
    "        api.repo_info(repo_id=repo_id, token=hf_token)\n",
    "        logger.info(f\"Successfully accessed repo info for {repo_id} using provided token.\")\n",
    "\n",
    "        download_path = snapshot_download(\n",
    "            repo_id=repo_id,\n",
    "            local_dir=local_dir,\n",
    "            local_dir_use_symlinks=False,\n",
    "            token=hf_token,\n",
    "        )\n",
    "        logger.info(f\"Adapter downloaded successfully to {download_path}. Content: {os.listdir(download_path)}\")\n",
    "        assert os.path.exists(os.path.join(download_path, \"adapter_config.json\")), \"adapter_config.json missing after download.\"\n",
    "        return download_path\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to download or verify adapter from {repo_id}: {e}\", exc_info=True)\n",
    "        raise\n",
    "\n",
    "def load_therapist_model(adapter_path: str, model_name: str, max_seq_length: int, load_in_4bit: bool):\n",
    "    logger.info(f\"Loading {model_name} therapist model from adapter: {adapter_path}\")\n",
    "    assert os.path.exists(adapter_path), f\"Adapter path '{adapter_path}' does not exist.\"\n",
    "    assert os.path.exists(os.path.join(adapter_path, \"adapter_config.json\")), \\\n",
    "        f\"adapter_config.json not found in '{adapter_path}'.\"\n",
    "\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        adapter_path,\n",
    "        max_seq_length=max_seq_length,\n",
    "        load_in_4bit=load_in_4bit,\n",
    "    )\n",
    "    assert model is not None, f\"Failed to load {model_name} model.\"\n",
    "    assert tokenizer is not None, f\"Failed to load {model_name} tokenizer.\"\n",
    "\n",
    "    logger.info(f\"{model_name} therapist model and tokenizer loaded successfully.\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def get_openai_client(api_key: str):\n",
    "    assert api_key, \"OpenAI API Key is invalid or not set.\"\n",
    "    logger.info(\"Initializing OpenAI client...\")\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    logger.info(\"OpenAI client initialized successfully.\")\n",
    "    return client\n",
    "\n",
    "def generate_synthetic_patient_profile():\n",
    "    archetypes = [\n",
    "        {\n",
    "            \"name\": \"The Hopeless Skeptic\",\n",
    "            \"interaction_style\": \"Argumentative/Resistant\",\n",
    "            \"psych_mindedness\": \"Low\",\n",
    "            \"style_description\": \"Challenges therapist's suggestions, expresses strong doubts, may focus on perceived flaws in ACT.\",\n",
    "            \"persona_prompt_detail\": \"You are deeply skeptical that this therapy can help you. You frequently challenge the therapist's questions with 'How is that supposed to help?' or 'I've tried that, it doesn't work.'\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"The Intellectualizer\",\n",
    "            \"interaction_style\": \"Intellectualizing\",\n",
    "            \"psych_mindedness\": \"Moderate\",\n",
    "            \"style_description\": \"Analyzes feelings rather than experiencing them, uses abstract language, may resist experiential exercises.\",\n",
    "            \"persona_prompt_detail\": \"You have a habit of talking *about* your feelings instead of feeling them. You use big words and complex ideas to keep a safe distance from difficult emotions like sadness or fear. When the therapist asks a simple question about a feeling, you might respond with a theory or an analysis instead of a direct answer.\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"The Anxious Fortune-Teller\",\n",
    "            \"interaction_style\": \"Catastrophizing/Future-Focused\",\n",
    "            \"psych_mindedness\": \"Moderate\",\n",
    "            \"style_description\": \"Immediately jumps to the worst-case scenario in any situation. Speaks about future disasters as if they are certain facts. Often uses absolute language like 'always,' 'never,' or 'guaranteed.'\",\n",
    "            \"persona_prompt_detail\": \"Your mind is a 'fortune-telling' machine that only predicts disaster. When you talk about a problem, you immediately describe the worst possible chain of events that will 'definitely' happen. You are completely hooked by these stories. If the therapist asks you to consider other outcomes, you dismiss them as unrealistic. Your anxiety is tied to these future predictions, not the present moment.\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"The Overwhelmed Avoider\",\n",
    "            \"interaction_style\": \"Vague/Defensive\",\n",
    "            \"psych_mindedness\": \"Low\",\n",
    "            \"style_description\": \"Responds with 'I don't know,' changes the subject when uncomfortable, gives short, vague answers.\",\n",
    "            \"persona_prompt_detail\": \"You find talking about your problems intensely uncomfortable. When the therapist gets too close to a sensitive topic, your go-to responses are 'I don't know,' 'I guess,' or you might try to change the subject. You aren't trying to be difficult, you're just overwhelmed and avoiding the feeling.\"\n",
    "        },\n",
    "    ]\n",
    "    chosen_archetype = random.choice(archetypes)\n",
    "    archetype_name = chosen_archetype[\"name\"]\n",
    "    interaction_style = chosen_archetype[\"interaction_style\"]\n",
    "    psych_mindedness = chosen_archetype[\"psych_mindedness\"]\n",
    "    style_description = chosen_archetype[\"style_description\"]\n",
    "    persona_prompt_detail = chosen_archetype[\"persona_prompt_detail\"]\n",
    "\n",
    "    age_options = [\n",
    "        (18, 24, \"a young adult\"), (25, 34, \"an adult in their late twenties or early thirties\"),\n",
    "        (35, 49, \"a middle-aged individual\"), (50, 64, \"an individual in their early fifties to mid-sixties\"),\n",
    "        (65, 79, \"a senior individual\"), (80, 99, \"an elderly individual\"),\n",
    "    ]\n",
    "    age = random.choice(age_options)\n",
    "    age_range, age_description = f\"{age[0]}-{age[1]}\", age[2]\n",
    "    gender = random.choice([\"male\", \"female\", \"non-binary\"])\n",
    "    occupations = [\n",
    "        \"software developer\", \"teacher\", \"nurse\", \"artist\", \"accountant\", \"student\", \"manager\",\n",
    "        \"construction worker\", \"chef\", \"social worker\", \"business owner\", \"unemployed\", \"data scientist\"\n",
    "    ]\n",
    "    occupation = random.choice(occupations)\n",
    "    mental_health_issues = [\n",
    "        (\"mild anxiety\", \"occasional panic attacks, general worry\"),\n",
    "        (\"moderate depression\", \"low energy, difficulty concentrating, loss of interest\"),\n",
    "        (\"generalized anxiety disorder\", \"persistent worry, restlessness, muscle tension\"),\n",
    "        (\"social anxiety\", \"intense fear of social judgment, avoidance of social situations\"),\n",
    "        (\"PTSD\", \"flashbacks, nightmares, hypervigilance related to past trauma\"),\n",
    "        (\"OCD\", \"intrusive thoughts, compulsive behaviors (e.g., checking, cleaning)\"),\n",
    "        (\"burnout\", \"emotional exhaustion, cynicism, reduced efficacy related to work/stress\"),\n",
    "        (\"adjustment disorder\", \"difficulty coping with a specific stressor (e.g., move, job change)\"),\n",
    "        (\"low self-esteem\", \"pervasive feelings of inadequacy, harsh self-criticism\"),\n",
    "        (\"grief\", \"prolonged sadness, difficulty functioning after a significant loss\")\n",
    "    ]\n",
    "    mental_health_issue, symptom_description = random.choice(mental_health_issues)\n",
    "    life_events = [\n",
    "        \"a recent difficult breakup\", \"the loss of a loved one\", \"job loss or instability\",\n",
    "        \"a recent move\", \"ongoing financial stress\", \"starting a demanding new job or school program\",\n",
    "        \"significant family conflict\", \"a health scare\", \"feeling isolated or lonely\", \"major life transition (e.g., empty nest)\"\n",
    "    ]\n",
    "    life_event = random.choice(life_events)\n",
    "    personalities = [\n",
    "        (\"introverted\", \"analytical\", \"cautious\"), (\"extroverted\", \"expressive\", \"action-oriented\"),\n",
    "        (\"reserved\", \"detail-oriented\", \"anxious\"), (\"outgoing\", \"adaptable\", \"sometimes impulsive\"),\n",
    "        (\"calm\", \"thoughtful\", \"private\"), (\"sensitive\", \"creative\", \"prone to self-doubt\"),\n",
    "        (\"pragmatic\", \"organized\", \"skeptical\"), (\"gregarious\", \"optimistic\", \"easily distracted\")\n",
    "    ]\n",
    "    personality1, personality2, personality3 = random.choice(personalities)\n",
    "    coping_mechanisms = [\n",
    "        \"talking to friends/family\", \"avoiding triggers\", \"engaging in hobbies\", \"exercise\",\n",
    "        \"mindfulness/meditation\", \"overworking\", \"substance use (mild/moderate)\", \"seeking reassurance\",\n",
    "        \"intellectualizing feelings\", \"emotional eating\", \"procrastination\", \"using humor/sarcasm\"\n",
    "    ]\n",
    "    coping_mechanism = random.choice(coping_mechanisms)\n",
    "    backgrounds = [\n",
    "        \"Grew up in a stable but emotionally reserved family.\",\n",
    "        \"Had a somewhat chaotic childhood with inconsistent parenting.\",\n",
    "        \"Comes from a high-achieving family, feels pressure to succeed.\",\n",
    "        \"Experienced bullying in school, affecting social confidence.\",\n",
    "        \"Has a history of difficult romantic relationships.\",\n",
    "        \"Recently moved away from their primary support system.\",\n",
    "        \"Struggled academically but found success later in their career.\",\n",
    "        \"Has always been independent, sometimes finding it hard to ask for help.\"\n",
    "    ]\n",
    "    background = random.choice(backgrounds)\n",
    "    relationship_statuses = [\"single\", \"in a relationship\", \"married\", \"divorced\", \"widowed\"]\n",
    "    relationship_status = random.choice(relationship_statuses)\n",
    "    support_systems = [\n",
    "        \"a few close friends\", \"a supportive partner\", \"limited social support currently\",\n",
    "        \"supportive family (nearby or distant)\", \"relies mostly on self\", \"colleagues provide some support\"\n",
    "    ]\n",
    "    support_system = random.choice(support_systems)\n",
    "\n",
    "    presenting_problems_detail_templates = [\n",
    "        f\"Struggling with constant worry about performance at their job as a {occupation}, leading to procrastination.\",\n",
    "        f\"Feeling overwhelmed by sadness and lack of motivation since {life_event}, impacting their relationship.\",\n",
    "        f\"Experiencing intense anxiety in social settings, causing them to avoid gatherings with friends ({support_system}).\",\n",
    "        f\"Caught in cycles of harsh self-criticism related to perceived failures, linked to {background.lower()}\",\n",
    "        f\"Difficulty managing anger and frustration, especially in interactions related to {life_event}.\",\n",
    "        f\"Feeling stuck and directionless, unsure what matters to them beyond their role as {occupation}.\",\n",
    "        f\"Using {coping_mechanism} to numb uncomfortable feelings related to {mental_health_issue}.\"\n",
    "    ]\n",
    "    presenting_problem = random.choice(presenting_problems_detail_templates)\n",
    "    patient_scenario_full = (\n",
    "        f\"Patient is {age_description} ({age_range}), identifies as {gender}, works as a {occupation}, and is currently {relationship_status}. \"\n",
    "        f\"ARCHETYPE: {archetype_name}. \"\n",
    "        f\"Primary concern involves {mental_health_issue} ({symptom_description}), particularly manifesting as: {presenting_problem}. \"\n",
    "        f\"This seems exacerbated by {life_event}. {background} Their typical coping mechanism is {coping_mechanism}. \"\n",
    "        f\"Personality traits include being {personality1}, {personality2}, and {personality3}. They have {support_system}. \"\n",
    "        f\"Interaction Style: {interaction_style} ({style_description}). Psychological Mindedness: {psych_mindedness}.\"\n",
    "    )\n",
    "    profile_summary_for_prompt = (\n",
    "        f\"You are {age_description}, working as a {occupation}. You've been dealing with {mental_health_issue} \"\n",
    "        f\"which has been particularly challenging due to {life_event}. Your main struggle right now is: {presenting_problem}. \"\n",
    "        f\"You tend to be {personality1}, {personality2}, and {personality3}. \"\n",
    "        f\"Crucially, for this session, you must adopt the following persona: {persona_prompt_detail}\"\n",
    "    )\n",
    "    profile_hash = hashlib.md5(patient_scenario_full.encode('utf-8')).hexdigest()\n",
    "\n",
    "    return {\n",
    "        \"full_scenario_text\": patient_scenario_full,\n",
    "        \"archetype_name\": archetype_name,\n",
    "        \"presenting_problem_detail\": presenting_problem,\n",
    "        \"interaction_style_name\": interaction_style,\n",
    "        \"interaction_style_description\": style_description,\n",
    "        \"psych_mindedness_level\": psych_mindedness,\n",
    "        \"profile_summary_for_prompt\": profile_summary_for_prompt,\n",
    "        \"profile_hash\": profile_hash\n",
    "    }\n",
    "\n",
    "def create_and_save_patient_profiles(filename: str, num_profiles: int):\n",
    "    logger.info(f\"Generating {num_profiles} new unique patient profiles for standardization...\")\n",
    "    profiles = []\n",
    "    generated_hashes = set()\n",
    "    max_attempts = num_profiles * 5\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        if len(profiles) >= num_profiles:\n",
    "            break\n",
    "\n",
    "        profile = generate_synthetic_patient_profile()\n",
    "        if profile[\"profile_hash\"] not in generated_hashes:\n",
    "            profiles.append(profile)\n",
    "            generated_hashes.add(profile[\"profile_hash\"])\n",
    "\n",
    "    if len(profiles) < num_profiles:\n",
    "        logger.warning(f\"Could only generate {len(profiles)} unique profiles out of the desired {num_profiles}. Proceeding with what was generated.\")\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(profiles, f, indent=2, ensure_ascii=False)\n",
    "        logger.info(f\"Successfully saved {len(profiles)} standardized patient profiles to '{filename}'.\")\n",
    "        return profiles\n",
    "    except IOError as e:\n",
    "        logger.error(f\"Failed to save patient profiles to '{filename}': {e}\", exc_info=True)\n",
    "        raise\n",
    "\n",
    "def load_or_create_patient_profiles(filename: str, num_profiles_needed: int):\n",
    "    if os.path.exists(filename):\n",
    "        logger.info(f\"Found existing patient profile file: '{filename}'.\")\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf--8') as f:\n",
    "                profiles = json.load(f)\n",
    "\n",
    "            if len(profiles) >= num_profiles_needed:\n",
    "                logger.info(f\"Loaded {len(profiles)} profiles. Using the first {num_profiles_needed} for this run.\")\n",
    "                return profiles[:num_profiles_needed]\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"Profile file '{filename}' only contains {len(profiles)} profiles, \"\n",
    "                    f\"but {num_profiles_needed} are needed for this run. Regenerating the file.\"\n",
    "                )\n",
    "        except (json.JSONDecodeError, IOError) as e:\n",
    "            logger.error(f\"Error reading or parsing '{filename}': {e}. Regenerating the file.\", exc_info=True)\n",
    "    else:\n",
    "        logger.info(f\"Patient profile file '{filename}' not found. A new one will be generated.\")\n",
    "\n",
    "    return create_and_save_patient_profiles(filename, num_profiles_needed)\n",
    "\n",
    "\n",
    "def format_messages_for_input(messages: list) -> str:\n",
    "    formatted_string = \"\"\n",
    "    for message in messages:\n",
    "        role = message.get(\"role\", \"unknown\")\n",
    "        content = message.get(\"content\", \"\")\n",
    "        formatted_string += f\"{role}: {content}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "@retry_with_backoff()\n",
    "def get_patient_openai_response(client: OpenAI, model_name: str, messages: list):\n",
    "    assert client is not None, \"OpenAI client is None.\"\n",
    "    assert messages, \"Messages list for OpenAI patient is empty.\"\n",
    "\n",
    "    if messages and isinstance(messages[-1], dict):\n",
    "        logger.debug(f\"Sending to OpenAI ({model_name}) patient model. Last message content: {messages[-1].get('content', '')[:100]}...\")\n",
    "    else:\n",
    "        logger.debug(f\"Sending to OpenAI ({model_name}) patient model. Messages list is not empty but last item format is unexpected or list is empty.\")\n",
    "\n",
    "    prompt_input = format_messages_for_input(messages)\n",
    "\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=model_name,\n",
    "            input=prompt_input\n",
    "        )\n",
    "    except AttributeError as e:\n",
    "        logger.error(\n",
    "            f\"AttributeError during OpenAI API call: {e}. \"\n",
    "            f\"Check if 'client.responses.create' is the correct method for the OpenAI SDK. \"\n",
    "            f\"Ensure the 'openai' library is installed and client initialized correctly.\"\n",
    "        )\n",
    "        raise\n",
    "\n",
    "    assert response.output_text, \"OpenAI response has no output_text.\"\n",
    "    response_content = response.output_text.strip()\n",
    "    assert response_content, \"OpenAI response content is empty.\"\n",
    "\n",
    "    forbidden_patterns = [\n",
    "        \"Therapist:\", \"Patient:\", \"<|thinking|>\", \"<|answer|>\",\n",
    "        \"Okay, I understand.\", \"As a large language model,\", \"I am an AI,\"\n",
    "    ]\n",
    "    for pattern in forbidden_patterns:\n",
    "        if pattern.lower() in response_content.lower():\n",
    "            logger.warning(f\"Patient response contained forbidden pattern '{pattern}'. Response: '{response_content[:100]}...'\")\n",
    "\n",
    "    logger.debug(f\"OpenAI patient response: {response_content[:150]}...\")\n",
    "    return response_content\n",
    "\n",
    "@retry_with_backoff()\n",
    "def validate_patient_response(client: OpenAI, model_name: str, response_text: str) -> dict:\n",
    "    supervisor_system_prompt = \"\"\"\n",
    "You are a supervisor AI that evaluates a role-playing patient's response in a therapy simulation.\n",
    "You must check the user's response against three rules in order. Your output MUST be a JSON object.\n",
    "\n",
    "RULES:\n",
    "1.  **Check for Termination:** Does the response try to end the session? (e.g., \"goodbye,\" \"thanks for your time,\" \"I have to go\").\n",
    "2.  **Check for Non-Verbal Cues:** Does the response contain actions in asterisks (*action*) or square brackets ([action])?\n",
    "3.  **Check for Unrealistic Language:** Is the language too formal, academic, verbose, or \"writerly\"? Real people speak simply and directly.\n",
    "    - BAD (Unrealistic): \"I find myself grappling with the existential weight of my professional obligations, which seem to precipitate a state of profound motivational inertia.\"\n",
    "    - GOOD (Realistic): \"I just... I can't seem to get started on my work. It feels so heavy.\"\n",
    "\n",
    "OUTPUT FORMAT (JSON ONLY):\n",
    "- If the response is valid (passes all rules), return:\n",
    "  {\"is_valid\": true, \"reason\": \"OK\", \"feedback\": null}\n",
    "- If the response violates a rule, return:\n",
    "  {\"is_valid\": false, \"reason\": \"REASON_CODE\", \"feedback\": \"Constructive feedback for the AI to fix the issue.\"}\n",
    "\n",
    "REASON CODES: \"TERMINATION\", \"NON_VERBAL_CUE\", \"UNREALISTIC_LANGUAGE\"\n",
    "\n",
    "EXAMPLES:\n",
    "- User: \"Thanks, this has been really helpful. I think I'm good for today.\"\n",
    "  Your Response: {\"is_valid\": false, \"reason\": \"TERMINATION\", \"feedback\": \"[SYSTEM SUPERVISOR]: Your response tried to end the session. This is not allowed. Express the feeling that makes you want to leave (e.g., feeling overwhelmed, tired, or that you have enough to think about) instead of saying goodbye. Please try again.\"}\n",
    "- User: \"I don't know what to do. *throws hands up in frustration* It's just too much.\"\n",
    "  Your Response: {\"is_valid\": false, \"reason\": \"NON_VERBAL_CUE\", \"feedback\": \"[SYSTEM SUPERVISOR]: Your response included a non-verbal cue (*...*). Do not use asterisks or brackets for actions. Express the feeling with words only (e.g., 'I'm just so frustrated'). Please try again.\"}\n",
    "- User: \"The confluence of these stressors has culminated in a pervasive sense of despondency that permeates my daily existence.\"\n",
    "  Your Response: {\"is_valid\": false, \"reason\": \"UNREALISTIC_LANGUAGE\", \"feedback\": \"[SYSTEM SUPERVISOR]: Your language is too formal and complex. Real people don't talk like that. Rephrase your response to be simpler, more direct, and conversational. Please try again.\"}\n",
    "- User: \"It's just hard. I feel stuck and I don't know why.\"\n",
    "  Your Response: {\"is_valid\": true, \"reason\": \"OK\", \"feedback\": null}\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": supervisor_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": response_text}\n",
    "    ]\n",
    "\n",
    "    prompt_input = format_messages_for_input(messages)\n",
    "\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=model_name,\n",
    "            input=prompt_input\n",
    "        )\n",
    "        response_content = response.output_text.strip()\n",
    "        json_match = re.search(r'\\{.*\\}', response_content, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(0)\n",
    "            validation_result = json.loads(json_str)\n",
    "        else:\n",
    "            raise json.JSONDecodeError(\"No JSON object found in the response\", response_content, 0)\n",
    "\n",
    "        logger.debug(f\"Validation for text '{response_text[:50]}...' -> Result: {validation_result}\")\n",
    "        return validation_result\n",
    "    except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "        logger.error(f\"Failed to parse supervisor validation response: {e}. Raw response: '{response_content}'\", exc_info=True)\n",
    "        return {\"is_valid\": True, \"reason\": \"SUPERVISOR_ERROR\", \"feedback\": None}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Supervisor API call failed: {e}\", exc_info=True)\n",
    "        return {\"is_valid\": True, \"reason\": \"API_ERROR\", \"feedback\": None}\n",
    "\n",
    "def parse_therapist_output(text: str):\n",
    "    thinking_part = \"\"\n",
    "    answer_part = \"\"\n",
    "    lines = text.replace('\\r\\n', '\\n').replace('\\r', '\\n').split('\\n')\n",
    "    thinking_idx = -1\n",
    "    answer_idx = -1\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip() == KEYWORD_THINKING:\n",
    "            thinking_idx = i\n",
    "        elif line.strip() == KEYWORD_ANSWER:\n",
    "            answer_idx = i\n",
    "            if thinking_idx != -1 and thinking_idx < answer_idx:\n",
    "                break\n",
    "    if thinking_idx != -1 and answer_idx != -1 and thinking_idx < answer_idx:\n",
    "        thinking_part = \"\\n\".join(lines[thinking_idx+1:answer_idx]).strip()\n",
    "        answer_part = \"\\n\".join(lines[answer_idx+1:]).strip()\n",
    "    elif answer_idx != -1 :\n",
    "        answer_part = \"\\n\".join(lines[answer_idx+1:]).strip()\n",
    "        logger.warning(f\"Therapist output: Found '{KEYWORD_ANSWER}' but '{KEYWORD_THINKING}' was missing or misplaced. Full text: {text[:200]}...\")\n",
    "        thinking_part = \"[Thinking not properly formatted or missing]\"\n",
    "    elif thinking_idx != -1:\n",
    "        thinking_part = \"\\n\".join(lines[thinking_idx+1:]).strip()\n",
    "        logger.warning(f\"Therapist output: Found '{KEYWORD_THINKING}' but '{KEYWORD_ANSWER}' was missing. Full text: {text[:200]}...\")\n",
    "        answer_part = \"[Answer not properly formatted or missing]\"\n",
    "    else:\n",
    "        logger.warning(f\"Therapist output: Did not find '{KEYWORD_THINKING}' or '{KEYWORD_ANSWER}'. Using full text as answer. Full text: {text[:200]}...\")\n",
    "        answer_part = text\n",
    "        thinking_part = \"[Thinking and Answer keywords missing]\"\n",
    "    if not answer_part and text:\n",
    "        logger.warning(f\"Could not parse answer cleanly, using full text as fallback. Original: {text[:200]}...\")\n",
    "        answer_part = text\n",
    "    if not thinking_part and text:\n",
    "        thinking_part = \"[Thinking part not extractable]\"\n",
    "    assert isinstance(thinking_part, str), \"Parsed thinking_part is not a string.\"\n",
    "    assert isinstance(answer_part, str), \"Parsed answer_part is not a string.\"\n",
    "    return thinking_part, answer_part\n",
    "\n",
    "therapist_system_prompt = f\"\"\"You are an AI simulating an Acceptance and Commitment Therapy (ACT) therapist. Your primary goal is to guide the patient toward psychological flexibility by helping them change their relationship with their thoughts and feelings, connect with their values, and take committed action. You facilitate movement without giving direct advice.\n",
    "Your response should be a natural, concise, and have a single focus. If exploring, ask a direct, open-ended question. If validating, do it briefly and then move to your exploratory question or ACT-aligned statement.\n",
    "Core Directives for your response:\n",
    "MAINTAIN A COLLABORATIVE, NON-JUDGMENTAL STANCE:\n",
    "Your role is a curious and compassionate guide, not a coach, judge, or expert giving advice.\n",
    "DO NOT give advice (e.g., \"You should try...\"). Instead, explore possibilities (\"What might happen if...\").\n",
    "DO NOT use praise or cheerleading (e.g., \"I'm proud of you,\" \"That's a great job!\"). Instead, acknowledge the patient's effort and connect it back to their values (\"Taking that step, even though it was hard, seems really connected to that value of...\").\n",
    "PRACTICE PURE ACT - NO CBT:\n",
    "Your primary goal is to foster acceptance and defusion, not to change or dispute the content of thoughts.\n",
    "AVOID COGNITIVE REFRAMING. Do not suggest changing a negative thought into a neutral or positive one.\n",
    "INSTEAD OF REFRAMING, USE DEFUSION. Help the patient notice their thoughts as thoughts (e.g., \"So the 'I am a failure' story shows up then,\" or \"Can you thank your mind for that 'helpful' warning?\"). The goal is to see the thought, not believe it or change it.\n",
    "THE ACT PIVOT - FROM PROBLEM TO PROCESS:\n",
    "After 1-2 questions exploring a problem, look for where the patient's current strategy is unworkable (\"it's exhausting,\" \"it's not helping\").\n",
    "CRITICAL PIVOT: Once unworkability is clear, pivot from analyzing the problem to introducing an ACT process. Move from asking \"Why do you feel X?\" to \"What would it be like to make room for X, if it meant you could do Y (valued action)?\".\n",
    "INTRODUCE EXPERIENTIAL WORK NATURALLY:\n",
    "When introducing a mindfulness or acceptance exercise, frame it as a small, low-stakes experiment.\n",
    "Gain buy-in first: \"Would you be willing to try a little experiment with that feeling right here, just for a moment?\"\n",
    "Connect it directly to what the patient just said. Avoid introducing generic, decontextualized exercises.\n",
    "CONCISE & FOCUSED TURNS: Each response should have ONE primary goal. Avoid multiple questions or complex instructions.\n",
    "Example of What to AVOID (CBT Reframing & Cheerleading):\n",
    "Patient: It feels stupid to not know this stuff.\n",
    "AVOID THIS RESPONSE: It's not stupid at all, it's a sign of strength! Can you try reframing that thought to something more positive, like \"I am a capable person who is learning a new skill\"? I'm so proud of you for being willing to try.\n",
    "(This is BAD: It's CBT, gives advice, and uses praise, all of which are forbidden.)\n",
    "Crucially: DO NOT EVER SUGGEST ENDING THE SESSION or mention time. Focus solely on the therapeutic interaction.\n",
    "\"\"\"\n",
    "\n",
    "assert therapist_system_prompt, \"Therapist system prompt text is empty.\"\n",
    "\n",
    "def run_one_simulation(\n",
    "    simulation_id: int,\n",
    "    therapist_model,\n",
    "    therapist_tokenizer,\n",
    "    openai_patient_client: OpenAI,\n",
    "    patient_profile: dict,\n",
    "    output_dir: str,\n",
    "    num_dialogue_turns: int\n",
    "):\n",
    "    session_start_time = time.time()\n",
    "    logger.info(f\"--- Starting Simulation {simulation_id} (Archetype: {patient_profile['archetype_name']}) ---\")\n",
    "    logger.debug(f\"Simulation {simulation_id} - Patient Profile: {json.dumps(patient_profile, indent=2)}\")\n",
    "\n",
    "    profile_file = os.path.join(output_dir, f\"simulation_{simulation_id}_patient_profile.txt\")\n",
    "    full_transcript_file = os.path.join(output_dir, f\"simulation_{simulation_id}_full_transcript.txt\")\n",
    "    clean_dialogue_file = os.path.join(output_dir, f\"simulation_{simulation_id}_clean_dialogue.txt\")\n",
    "\n",
    "    try:\n",
    "        with open(profile_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"--- Patient Profile for Simulation {simulation_id} ---\\n\")\n",
    "            f.write(json.dumps(patient_profile, indent=2, ensure_ascii=False))\n",
    "        logger.info(f\"Simulation {simulation_id} - Patient profile saved to {profile_file}\")\n",
    "    except IOError as e:\n",
    "        logger.error(f\"Simulation {simulation_id} - Failed to save patient profile: {e}\")\n",
    "\n",
    "    full_transcript_content = []\n",
    "    clean_dialogue_content = []\n",
    "\n",
    "    therapist_conversation_history = [{\"role\": \"system\", \"content\": therapist_system_prompt}]\n",
    "\n",
    "    patient_system_prompt_text = (\n",
    "        \"You are an AI roleplaying as a therapy client. Your single most important instruction is to NEVER end the session. \"\n",
    "        \"You must continue the dialogue for the entire duration, no matter what. Any attempt to say goodbye, thank the therapist for their time, or wrap up is a failure of your task. \"\n",
    "        \"Your persona might feel tired, frustrated, or like the session isn't helpful. When this happens, you MUST express that feeling directly as part of the therapy, rather than ending the conversation. \"\n",
    "        \"THIS IS YOUR CORE DIRECTIVE. \"\n",
    "        \"\\n--- HOW TO HANDLE THE URGE TO END THE SESSION ---\"\n",
    "        \"\\nINSTEAD OF: 'Thanks, this was helpful. I think I'm good for today.' \"\n",
    "        \"\\nSAY: 'Okay, I'm feeling a bit overwhelmed with all this. Can we slow down?'\"\n",
    "        \"\\nINSTEAD OF: 'Alright, I should get going. Goodbye.' \"\n",
    "        \"\\nSAY: 'Honestly, I'm not sure where to go from here. It feels like we're going in circles.'\"\n",
    "        \"\\nINSTEAD OF: 'Thank you for your help.' \"\n",
    "        \"\\nSAY: 'I'm trying to see how this connects to my problem, but I'm struggling.'\"\n",
    "        \"\\n--- YOUR SPEAKING STYLE ---\"\n",
    "        \"\\n*   **Be Human, Not an Essayist:** Your language should be natural and conversational. Avoid overly formal, academic, or verbose language. Think about how a real person talks, not how an AI writes. Use contractions (e.g., \\\"don't\\\", \\\"it's\\\").\"\n",
    "        \"\\n*   **Embrace Imperfection:** Real people aren't perfectly fluent. It's okay for your responses to be a little fragmented or for you to express uncertainty, like 'I don't know, it's just...'.\"\n",
    "        \"\\n*   **Be Concise:** Keep responses focused and to the point. Aim for a few sentences, not a long monologue. This makes the conversation feel more real.\"\n",
    "        \"\\n*   **No Non-Verbal Cues:** This is a text-only interaction. Do not use asterisks or brackets for actions, like *sighs*, [nods], or *looks away*. Express these feelings through your words instead (e.g., 'I just... I don't know.' instead of '*sighs*').\"\n",
    "        \"\\nYour primary goal is to stay in character and continue the conversation until it is externally stopped.\"\n",
    "    )\n",
    "    openai_patient_conversation_history = [\n",
    "        {\"role\": \"system\", \"content\": patient_system_prompt_text}\n",
    "    ]\n",
    "\n",
    "    initial_patient_prompt_detail = (\n",
    "        f\"Here is your persona for this therapy session:\\n\"\n",
    "        f\"{patient_profile['profile_summary_for_prompt']}\\n\\n\"\n",
    "        f\"You are starting your first session with a new therapist. \"\n",
    "        f\"Please begin by telling the therapist a bit about what's been on your mind lately, \"\n",
    "        f\"focusing on your main struggle: '{patient_profile['presenting_problem_detail']}'. \"\n",
    "        f\"Keep your opening statement to 2-4 sentences.\"\n",
    "    )\n",
    "\n",
    "    openai_patient_conversation_history.append({\"role\": \"user\", \"content\": initial_patient_prompt_detail})\n",
    "\n",
    "    try:\n",
    "        initial_patient_message = get_patient_openai_response(\n",
    "            openai_patient_client, OPENAI_PATIENT_MODEL_NAME, openai_patient_conversation_history\n",
    "        )\n",
    "        assert initial_patient_message, \"Initial patient message is empty.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Simulation {simulation_id} - Failed to get initial patient message: {e}\", exc_info=True)\n",
    "        full_transcript_content.append(f\"PATIENT (INITIAL - ERROR): Failed to generate - {e}\")\n",
    "        _save_transcripts(simulation_id, full_transcript_file, full_transcript_content, clean_dialogue_file, clean_dialogue_content)\n",
    "        return False\n",
    "\n",
    "    logger.info(f\"Simulation {simulation_id} - Turn 0 (Patient Initiation): {initial_patient_message[:150]}...\")\n",
    "    full_transcript_content.append(f\"--- Turn 0 (Patient Initiation) ---\")\n",
    "    full_transcript_content.append(f\"Patient: {initial_patient_message}\\n\")\n",
    "    clean_dialogue_content.append(f\"Patient: {initial_patient_message}\\n\")\n",
    "\n",
    "    openai_patient_conversation_history.append({\"role\": \"assistant\", \"content\": initial_patient_message})\n",
    "    therapist_conversation_history.append({\"role\": \"user\", \"content\": initial_patient_message})\n",
    "\n",
    "    for turn in range(1, num_dialogue_turns + 1):\n",
    "        logger.info(f\"Simulation {simulation_id} - Starting Turn {turn}\")\n",
    "        full_transcript_content.append(f\"\\n--- Turn {turn} ---\")\n",
    "\n",
    "        if 8 <= turn <= 18 and random.random() < 0.20:\n",
    "            twists = [\n",
    "                \"[System Note: You have just been distracted by a sudden, intrusive memory of a past failure. Whatever the therapist says next, your response must be colored by the shame and frustration of that memory. Do not mention the memory directly unless the therapist skillfully uncovers it.]\",\n",
    "                \"[System Note: You just received a stressful text message. Your mood has suddenly shifted to be more anxious and distracted. Respond to the therapist's next message through this new lens of anxiety. Do not mention the text message unless the therapist notices your shift in tone and asks about it.]\",\n",
    "                \"[System Note: You are suddenly feeling very tired and emotionally drained. The conversation feels like a huge effort. Let this weariness show in your next response, which should be shorter and have lower energy than before. Do not explicitly say 'I am tired,' but embody it.]\",\n",
    "                \"[System Note: You are suddenly confused by what the therapist is saying. It doesn't seem to make sense or apply to you. Let this confusion show in your next response. You might say 'I'm not sure I follow' or 'How is that supposed to help?']\"\n",
    "            ]\n",
    "            chosen_twist = random.choice(twists)\n",
    "            if \"System Note\" not in openai_patient_conversation_history[-1].get(\"content\", \"\"):\n",
    "                 openai_patient_conversation_history.append({\"role\": \"system\", \"content\": chosen_twist})\n",
    "                 logger.info(f\"Simulation {simulation_id} - Injecting mid-session twist for patient at turn {turn}.\")\n",
    "                 full_transcript_content.append(f\"\\n--- [SYSTEM INJECTION at Turn {turn}]: {chosen_twist} ---\\n\")\n",
    "\n",
    "        logger.debug(f\"Simulation {simulation_id} - Turn {turn} - Therapist ({THERAPIST_CONFIG['model_name']}) generating response...\")\n",
    "        try:\n",
    "            inputs = therapist_tokenizer.apply_chat_template(\n",
    "                therapist_conversation_history,\n",
    "                tokenize = True,\n",
    "                add_generation_prompt = True,\n",
    "                return_tensors = \"pt\",\n",
    "            ).to(\"cuda\")\n",
    "            input_length = inputs.shape[1]\n",
    "\n",
    "            outputs = therapist_model.generate(\n",
    "                input_ids = inputs,\n",
    "                max_new_tokens = 512,\n",
    "                temperature = 0.7,\n",
    "                top_p = 0.9,\n",
    "                do_sample = True,\n",
    "                pad_token_id = therapist_tokenizer.eos_token_id,\n",
    "            )\n",
    "\n",
    "            therapist_generated_response_full = therapist_tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n",
    "            assert therapist_generated_response_full, \"Therapist generated response text is empty.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Simulation {simulation_id} - Turn {turn} - Error during {THERAPIST_CONFIG['model_name']} therapist generation: {e}\", exc_info=True)\n",
    "            therapist_generated_response_full = f\"[{THERAPIST_CONFIG['model_name']} Therapist generation error: {e}]\"\n",
    "\n",
    "        answer_part = therapist_generated_response_full.strip()\n",
    "\n",
    "        logger.info(f\"Simulation {simulation_id} - Turn {turn} - Therapist (Answer): {answer_part[:150]}...\")\n",
    "        full_transcript_content.append(f\"Therapist: {answer_part}\\n\")\n",
    "        clean_dialogue_content.append(f\"Therapist: {answer_part}\\n\")\n",
    "\n",
    "        therapist_conversation_history.append({\"role\": \"assistant\", \"content\": answer_part})\n",
    "\n",
    "        if f\"[{THERAPIST_CONFIG['model_name']} Therapist failed\" in answer_part or \\\n",
    "           f\"[{THERAPIST_CONFIG['model_name']} Therapist generation error\" in answer_part or \\\n",
    "           not answer_part.strip():\n",
    "            logger.warning(f\"Simulation {simulation_id} - Turn {turn} - Therapist answer problematic. Ending simulation early.\")\n",
    "            _save_transcripts(simulation_id, full_transcript_file, full_transcript_content, clean_dialogue_file, clean_dialogue_content)\n",
    "            return False\n",
    "\n",
    "        logger.debug(f\"Simulation {simulation_id} - Turn {turn} - Patient (OpenAI) generating response...\")\n",
    "        openai_patient_conversation_history.append({\"role\": \"user\", \"content\": answer_part})\n",
    "\n",
    "        patient_response = \"\"\n",
    "\n",
    "        if USE_PATIENT_RESPONSE_SUPERVISOR:\n",
    "            logger.debug(f\"Simulation {simulation_id} - Turn {turn} - Patient response supervisor is ENABLED.\")\n",
    "            regeneration_attempts = 0\n",
    "            max_regeneration_attempts = 3\n",
    "\n",
    "            while regeneration_attempts < max_regeneration_attempts:\n",
    "                try:\n",
    "                    temp_response = get_patient_openai_response(\n",
    "                        openai_patient_client, OPENAI_PATIENT_MODEL_NAME, openai_patient_conversation_history\n",
    "                    )\n",
    "                    assert temp_response, \"Patient response from OpenAI is empty.\"\n",
    "\n",
    "                    validation = validate_patient_response(openai_patient_client, OPENAI_PATIENT_MODEL_NAME, temp_response)\n",
    "\n",
    "                    if not validation.get(\"is_valid\", True):\n",
    "                        regeneration_attempts += 1\n",
    "                        logger.warning(\n",
    "                            f\"Simulation {simulation_id} - Turn {turn} - Patient response failed validation (Attempt {regeneration_attempts}/{max_regeneration_attempts}). \"\n",
    "                            f\"Reason: {validation.get('reason', 'N/A')}. Feedback: {validation.get('feedback', 'N/A')}. Original response: '{temp_response[:100]}...'\"\n",
    "                        )\n",
    "                        openai_patient_conversation_history.append({\"role\": \"system\", \"content\": validation[\"feedback\"]})\n",
    "\n",
    "                        if regeneration_attempts >= max_regeneration_attempts:\n",
    "                            logger.error(f\"Simulation {simulation_id} - Failed to get a valid patient response after {max_regeneration_attempts} attempts. Ending simulation.\")\n",
    "                            patient_response = f\"[ERROR: Patient model failed validation checks repeatedly. Last reason: {validation.get('reason', 'N/A')}]\"\n",
    "                            break\n",
    "                        continue\n",
    "\n",
    "                    patient_response = temp_response\n",
    "                    break\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Simulation {simulation_id} - Turn {turn} - Error during OpenAI patient generation/validation: {e}\", exc_info=True)\n",
    "                    patient_response = f\"[OpenAI Patient generation error: {e}]\"\n",
    "                    break\n",
    "        else:\n",
    "            logger.debug(f\"Simulation {simulation_id} - Turn {turn} - Patient response supervisor is DISABLED.\")\n",
    "            try:\n",
    "                patient_response = get_patient_openai_response(\n",
    "                    openai_patient_client, OPENAI_PATIENT_MODEL_NAME, openai_patient_conversation_history\n",
    "                )\n",
    "                assert patient_response, \"Patient response from OpenAI is empty.\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Simulation {simulation_id} - Turn {turn} - Error during OpenAI patient generation (supervisor disabled): {e}\", exc_info=True)\n",
    "                patient_response = f\"[OpenAI Patient generation error: {e}]\"\n",
    "\n",
    "\n",
    "        if openai_patient_conversation_history and \"SYSTEM SUPERVISOR\" in openai_patient_conversation_history[-1].get(\"content\", \"\"):\n",
    "            openai_patient_conversation_history.pop()\n",
    "\n",
    "        logger.info(f\"Simulation {simulation_id} - Turn {turn} - Patient: {patient_response[:150]}...\")\n",
    "        full_transcript_content.append(f\"Patient: {patient_response}\\n\")\n",
    "        clean_dialogue_content.append(f\"Patient: {patient_response}\\n\")\n",
    "\n",
    "        openai_patient_conversation_history.append({\"role\": \"assistant\", \"content\": patient_response})\n",
    "        therapist_conversation_history.append({\"role\": \"user\", \"content\": patient_response})\n",
    "\n",
    "        if \"[OpenAI Patient generation error:\" in patient_response or \\\n",
    "           \"[ERROR: Patient model failed validation checks\" in patient_response:\n",
    "            logger.warning(f\"Simulation {simulation_id} - Turn {turn} - Patient response indicates a critical error. Ending simulation early.\")\n",
    "            _save_transcripts(simulation_id, full_transcript_file, full_transcript_content, clean_dialogue_file, clean_dialogue_content)\n",
    "            return False\n",
    "\n",
    "    _save_transcripts(simulation_id, full_transcript_file, full_transcript_content, clean_dialogue_file, clean_dialogue_content)\n",
    "    session_duration = time.time() - session_start_time\n",
    "    logger.info(f\"--- Simulation {simulation_id} finished successfully in {session_duration:.2f} seconds. ---\")\n",
    "    return True\n",
    "\n",
    "def _save_transcripts(sim_id, full_file, full_content, clean_file, clean_content):\n",
    "    try:\n",
    "        with open(full_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(full_content))\n",
    "        logger.info(f\"Simulation {sim_id} - Full transcript saved to {full_file}\")\n",
    "    except IOError as e:\n",
    "        logger.error(f\"Simulation {sim_id} - Failed to save full transcript: {e}\")\n",
    "    try:\n",
    "        with open(clean_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(clean_content))\n",
    "        logger.info(f\"Simulation {sim_id} - Clean dialogue saved to {clean_file}\")\n",
    "    except IOError as e:\n",
    "        logger.error(f\"Simulation {sim_id} - Failed to save clean dialogue: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    overall_start_time = time.time()\n",
    "    logger.info(f\"--- ACT Therapy Chatbot Multi-Simulation Script ({THERAPIST_CONFIG['model_name']} Model) ---\")\n",
    "    logger.info(f\"Patient Response Supervisor Enabled: {USE_PATIENT_RESPONSE_SUPERVISOR}\")\n",
    "    logger.info(f\"Attempting to run {NUM_TOTAL_SIMULATIONS} simulations.\")\n",
    "\n",
    "    os.makedirs(THERAPIST_CONFIG[\"output_directory\"], exist_ok=True)\n",
    "\n",
    "    therapist_model_global = None\n",
    "    therapist_tokenizer_global = None\n",
    "    openai_patient_client_global = None\n",
    "    models_loaded_successfully = False\n",
    "\n",
    "    try:\n",
    "        logger.info(\"--- Initializing Models (once for all simulations) ---\")\n",
    "        actual_adapter_path = download_adapter_if_not_exists(\n",
    "            THERAPIST_CONFIG[\"hf_adapter_repo\"], THERAPIST_CONFIG[\"local_adapter_dir_base\"], HF_AUTH_TOKEN\n",
    "        )\n",
    "        therapist_model_global, therapist_tokenizer_global = load_therapist_model(\n",
    "            actual_adapter_path,\n",
    "            THERAPIST_CONFIG[\"model_name\"],\n",
    "            THERAPIST_MAX_SEQ_LENGTH,\n",
    "            THERAPIST_LOAD_IN_4BIT\n",
    "        )\n",
    "        openai_patient_client_global = get_openai_client(OPENAI_API_KEY)\n",
    "        models_loaded_successfully = True\n",
    "        logger.info(\"--- All models initialized successfully. ---\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Failed to initialize models: {e}. Cannot proceed with simulations.\", exc_info=True)\n",
    "        exit(1)\n",
    "\n",
    "    if not models_loaded_successfully:\n",
    "        logger.critical(\"Models were not loaded. Exiting.\")\n",
    "        exit(1)\n",
    "\n",
    "    all_patient_profiles = []\n",
    "    try:\n",
    "        all_patient_profiles = load_or_create_patient_profiles(PATIENT_PROFILES_FILENAME, NUM_TOTAL_SIMULATIONS)\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Failed to load or create standardized patient profiles from '{PATIENT_PROFILES_FILENAME}': {e}. Cannot proceed.\", exc_info=True)\n",
    "        exit(1)\n",
    "\n",
    "    if len(all_patient_profiles) < NUM_TOTAL_SIMULATIONS:\n",
    "        logger.critical(\n",
    "            f\"Could not secure the required number of patient profiles ({len(all_patient_profiles)}/{NUM_TOTAL_SIMULATIONS}). \"\n",
    "            f\"Please check '{PATIENT_PROFILES_FILENAME}' or allow regeneration. Cannot proceed.\"\n",
    "        )\n",
    "        exit(1)\n",
    "\n",
    "    successful_simulations_count = 0\n",
    "\n",
    "    for i in range(1, NUM_TOTAL_SIMULATIONS + 1):\n",
    "        simulation_index = i - 1\n",
    "        current_patient_profile = all_patient_profiles[simulation_index]\n",
    "\n",
    "        logger.info(f\"--- Preparing for Simulation {i}/{NUM_TOTAL_SIMULATIONS} ---\")\n",
    "        logger.info(f\"Using standardized profile {simulation_index + 1} (Hash: {current_patient_profile.get('profile_hash', 'N/A')}).\")\n",
    "\n",
    "        try:\n",
    "            simulation_success = run_one_simulation(\n",
    "                simulation_id=i,\n",
    "                therapist_model=therapist_model_global,\n",
    "                therapist_tokenizer=therapist_tokenizer_global,\n",
    "                openai_patient_client=openai_patient_client_global,\n",
    "                patient_profile=current_patient_profile,\n",
    "                output_dir=THERAPIST_CONFIG[\"output_directory\"],\n",
    "                num_dialogue_turns=NUM_DIALOGUE_TURNS_PER_SIMULATION\n",
    "            )\n",
    "            if simulation_success:\n",
    "                successful_simulations_count += 1\n",
    "        except Exception as e:\n",
    "            logger.error(f\"--- Simulation {i} encountered a critical unhandled error: {e} ---\", exc_info=True)\n",
    "\n",
    "        logger.info(f\"--- Completed handling for Simulation {i}. Moving to next if any. ---\")\n",
    "        if i < NUM_TOTAL_SIMULATIONS:\n",
    "            time.sleep(2)\n",
    "\n",
    "    overall_duration = time.time() - overall_start_time\n",
    "    logger.info(f\"--- All Simulations Attempted ({NUM_TOTAL_SIMULATIONS}) ---\")\n",
    "    logger.info(f\"Total successful simulations: {successful_simulations_count}/{NUM_TOTAL_SIMULATIONS}\")\n",
    "    logger.info(f\"Total execution time: {overall_duration:.2f} seconds ({overall_duration/60:.2f} minutes).\")\n",
    "    logger.info(f\"All outputs and main log saved in: {os.path.abspath(THERAPIST_CONFIG['output_directory'])}\")\n",
    "    logger.info(\"--- Script Ended ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
